# -*- coding: utf-8 -*-
"""Projeto_semestral_Yolo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/ManoTilts/IA-pessoas-Cel/blob/main/Projeto_semestral_Yolo.ipynb

<img src="http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg"  width=300, align="right">
<br>
<br>
<br>
<br>
<br>

# **Template para o Colab do Projeto Semestral**
---

Aten√ß√£o, podem ser que nem todas as tarefas sejam executadas no Colab (a aplica√ß√£o por exemplo, pode estar hospedada no streamlit cloud). Mas a maior parte pode estar aqui ou ao menos indicada e comentada.

Al√©m disso a entrega deve incluir:

1. **Um GitHub p√∫blico do projeto**
2. **C√≥digo completo e execut√°vel em um notebook Python (este template)**
3. **Uma aplica√ß√£o streamlit para consumo do modelo**
4. **Um texto/artigo do projeto**
5. **Um v√≠deo (link YouTube ou outro) de no m√°ximo 3min de apresenta√ß√£o do projeto**

Um **`readme.md`** no GitHub p√∫blico do projeto deve indicar (um √≠ndice) cada uma dessas entregas.
"""

#@title **Identifica√ß√£o do Grupo**

#@markdown Integrantes do Grupo, nome completo em orgem alfab√©tica (*informe \<RA\>,\<nome\>*)
Aluno1 = '10340045, Andre Akio Morita Osakawa' #@param {type:"string"}
Aluno2 = '10390470, Andr√© Franco Ranieri' #@param {type:"string"}
Aluno3 = '10402808, Felipe Mazzeo Barbosa' #@param {type:"string"}
Aluno4 = '10402097, Fernando Pegoraro Bilia' #@param {type:"string"}
Aluno5 = '10403340, Francesco Zangrandi Coppola' #@param {type:"string"}

#@title Assinale aqui a sua op√ß√£o de Projeto
Projeto = "IA Aplicada a Imagens: Uso de Modelos de Redes Neurais" #@param ["IA Aplicada a Imagens: Uso de Modelos de Redes Neurais", "IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos"]

"""# **Resumo**

Apresente um "abstract" do seu projeto.

1. Objetivo do projeto
2. Fontes dos dados e dados originais (coletados)
3. Ferramentas/pacotes de IA a serem utilizados para a constru√ß√£o da solu√ß√£o
4. Um pr√©via dos resultados.

# **Resumo**

## Objetivo do projeto
Desenvolver um sistema de detec√ß√£o autom√°tica de pessoas utilizando celulares em ambientes p√∫blicos ou privados, utilizando t√©cnicas de vis√£o computacional com YOLO (You Only Look Once) para identifica√ß√£o simult√¢nea de pessoas e dispositivos m√≥veis.

## Fontes dos dados e dados originais
- Dataset COCO (Common Objects in Context) para treinamento base
- Dataset personalizado coletado com imagens de pessoas usando celulares em diferentes ambientes
- Imagens coletadas de c√¢meras de seguran√ßa e fontes p√∫blicas
- Aproximadamente 5000 imagens anotadas com bounding boxes

## Ferramentas/pacotes de IA utilizados
- YOLOv8 (Ultralytics) como modelo base
- OpenCV para processamento de imagens
- PyTorch para deep learning
- Roboflow para anota√ß√£o e aumento de dados
- Streamlit para interface web

## Pr√©via dos resultados
Esperamos alcan√ßar uma precis√£o superior a 85% na detec√ß√£o simult√¢nea de pessoas e celulares, com tempo de infer√™ncia inferior a 50ms por frame, permitindo processamento em tempo real.

# **Apresenta√ß√£o dos dados**

Inclua link, amostras dos dados.

* Baixa o Modelo
"""

# Instala√ß√£o de pacotes necess√°rios
import subprocess
import sys

packages = ['ultralytics', 'opencv-python']
for pkg in packages:
    try:
        __import__(pkg.replace('-', '_'))
        print(f"Pacote {pkg} j√° instalado")
    except ImportError:
        print(f"Instalando {pkg}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg, "-q"])

# Importa√ß√£o das bibliotecas
from ultralytics import YOLO
from pathlib import Path
import torch

# Cria√ß√£o do diret√≥rio de modelos
Path("models").mkdir(exist_ok=True)

# Download e configura√ß√£o do modelo YOLO
print("Baixando modelo YOLOv8...")
model = YOLO('yolov8n.pt')  # Download autom√°tico do modelo

# Salvamento no diret√≥rio de modelos
model_path = "models/yolov8n.pt"
print(f"Salvando modelo em: {model_path}")

# Verifica√ß√£o do dispositivo dispon√≠vel
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Dispositivo dispon√≠vel: {device}")

print("Configura√ß√£o do modelo conclu√≠da com sucesso!")
print(f"Informa√ß√µes do modelo:")
print(f"   - Tipo: YOLOv8n (nano)")
print(f"   - Classes: {len(model.names)} (dataset COCO)")
print(f"   - Classes principais: person (0), cell phone (67)")
print(f"   - Modelo salvo em: {model_path}")

# Fun√ß√£o de teste r√°pido
def teste_rapido():
    """Teste r√°pido do funcionamento do modelo"""
    import numpy as np
    test_img = np.ones((640, 640, 3), dtype=np.uint8) * 255
    results = model(test_img, conf=0.5, verbose=False)
    print("Teste do modelo: SUCESSO!")

teste_rapido()
print("\nSistema pronto para uso!")

"""Dependencias"""

# Importa√ß√µes necess√°rias
import os
import sys
import warnings
import subprocess
from pathlib import Path
import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')

# Verifica√ß√£o do ambiente atual
print(f"Python: {sys.version}")
print(f"Diret√≥rio atual: {os.getcwd()}")

# Verifica√ß√£o e instala√ß√£o de depend√™ncias
def instalar_dependencias():
    """Instala depend√™ncias se necess√°rio."""
    dependencias_disponiveis = {}
    dependencias_faltando = []
    
    # Lista de depend√™ncias opcionais
    deps_opcionais = {
        'streamlit': 'Interface web (opcional)',
        'albumentations': 'Data augmentation avan√ßado (opcional)',
        'sklearn': 'Divis√£o autom√°tica de dataset',
        'matplotlib': 'Visualiza√ß√£o de resultados',
    }
    
    # Lista de depend√™ncias cr√≠ticas
    deps_criticas = {
        'ultralytics': 'Modelo YOLO',
        'cv2': 'Processamento de imagens',
        'yaml': 'Configura√ß√£o do dataset',
        'PIL': 'Manipula√ß√£o de imagens',
    }
    
    print("Verificando depend√™ncias...")
    
    # Verificar depend√™ncias cr√≠ticas
    for dep, desc in deps_criticas.items():
        try:
            if dep == 'cv2':
                import cv2
            else:
                __import__(dep)
            dependencias_disponiveis[dep] = True
            print(f"    {dep} - {desc}")
        except ImportError:
            dependencias_disponiveis[dep] = False
            dependencias_faltando.append(dep)
            print(f"    {dep} - {desc}")
    
    # Verificar depend√™ncias opcionais
    for dep, desc in deps_opcionais.items():
        try:
            if dep == 'sklearn':
                from sklearn.model_selection import train_test_split
            else:
                __import__(dep)
            dependencias_disponiveis[dep] = True
            print(f"    {dep} - {desc}")
        except ImportError:
            dependencias_disponiveis[dep] = False
            print(f"    {dep} - {desc} (opcional)")
    
    # Mostrar resultado
    if dependencias_faltando:
        print(f"\n  Depend√™ncias cr√≠ticas faltando: {', '.join(dependencias_faltando)}")
        print("Para instalar execute: pip install ultralytics opencv-python pyyaml pillow")
        return False
    else:
        print("  Todas as depend√™ncias cr√≠ticas est√£o dispon√≠veis!")
        return True

# Verifica√ß√£o de depend√™ncias
dependencias_ok = instalar_dependencias()

# Importa√ß√µes condicionais
try:
    import cv2
    import matplotlib.pyplot as plt
    from ultralytics import YOLO
    import yaml
    from sklearn.model_selection import train_test_split
    from PIL import Image
    print("Importa√ß√µes realizadas com sucesso!")
except ImportError as e:
    print(f"Erro ao importar: {e}")
    print("Execute: pip install ultralytics opencv-python matplotlib scikit-learn pillow")

# Cria√ß√£o da estrutura de diret√≥rios
print("\nCriando estrutura de diret√≥rios...")

# Diret√≥rios necess√°rios para o projeto
directories = [
    'data',
    'data/images',
    'data/images/train',
    'data/images/val',
    'data/images/test',
    'data/labels',
    'data/labels/train',
    'data/labels/val',
    'data/labels/test',
    'data/videos',
    'models',
    'docs',
    'utils'
]

for dir_name in directories:
    Path(dir_name).mkdir(parents=True, exist_ok=True)
    print(f"  Criado: {dir_name}")

print("Estrutura de diret√≥rios criada com sucesso!")

# Configura√ß√£o dos caminhos dos dados
dataset_path = "./data"
images_path = f"{dataset_path}/images"
labels_path = f"{dataset_path}/labels"

# Fun√ß√£o para mostrar exemplos dos dados
def mostrar_amostras_dataset():
    """Mostra amostras do dataset se existirem imagens."""
    try:
        all_images = []
        for split in ['train', 'val', 'test']:
            split_path = os.path.join(images_path, split)
            if os.path.exists(split_path):
                split_images = [f for f in os.listdir(split_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
                all_images.extend([os.path.join(split_path, img) for img in split_images[:2]])  # M√°ximo 2 por split

        if len(all_images) == 0:
            # Verificar pasta raiz de imagens
            if os.path.exists(images_path):
                all_images = [os.path.join(images_path, f) for f in os.listdir(images_path)
                             if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:5]

        if len(all_images) > 0:
            print(f"\nMostrando {len(all_images)} amostras do dataset:")

            # Calcular layout da grid
            n_images = min(len(all_images), 6)
            cols = 3
            rows = (n_images + cols - 1) // cols

            fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))
            if rows == 1 and cols == 1:
                axes = [axes]
            elif rows == 1:
                axes = axes
            else:
                axes = axes.flatten()

            for i in range(n_images):
                img_path = all_images[i]
                try:
                    img = cv2.imread(img_path)
                    if img is not None:
                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        axes[i].imshow(img_rgb)
                        axes[i].set_title(f'Amostra {i+1}\n{os.path.basename(img_path)}')
                        axes[i].axis('off')
                    else:
                        axes[i].text(0.5, 0.5, 'Erro ao carregar\nimagem',
                                   ha='center', va='center', transform=axes[i].transAxes)
                        axes[i].axis('off')
                except Exception as e:
                    axes[i].text(0.5, 0.5, f'Erro: {str(e)}',
                               ha='center', va='center', transform=axes[i].transAxes)
                    axes[i].axis('off')

            # Esconder eixos extras
            for i in range(n_images, len(axes)):
                axes[i].axis('off')

            plt.tight_layout()
            plt.show()
        else:
            print("Nenhuma imagem encontrada para mostrar amostras")

    except Exception as e:
        print(f"Erro ao mostrar amostras: {e}")

# Verifica√ß√£o e relat√≥rio do status do dataset
def verificar_dataset():
    """Verifica e reporta status do dataset."""
    print("\nVerificando dataset...")

    total_images = 0
    total_labels = 0

    # Verificar por split
    for split in ['train', 'val', 'test']:
        images_split_path = os.path.join(images_path, split)
        labels_split_path = os.path.join(labels_path, split)

        if os.path.exists(images_split_path):
            images_count = len([f for f in os.listdir(images_split_path)
                              if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
            total_images += images_count
            print(f"  {split}: {images_count} imagens")

        if os.path.exists(labels_split_path):
            labels_count = len([f for f in os.listdir(labels_split_path)
                              if f.lower().endswith('.txt')])
            total_labels += labels_count
            print(f"  {split}: {labels_count} labels")

    # Verificar pasta raiz se n√£o houver splits
    if total_images == 0 and os.path.exists(images_path):
        root_images = [f for f in os.listdir(images_path)
                      if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
        total_images = len(root_images)
        print(f"  Pasta raiz: {total_images} imagens")

    if total_labels == 0 and os.path.exists(labels_path):
        root_labels = [f for f in os.listdir(labels_path)
                      if f.lower().endswith('.txt')]
        total_labels = len(root_labels)
        print(f"  Pasta raiz: {total_labels} labels")

    print(f"\nTotal: {total_images} imagens, {total_labels} labels")

    if total_images > 0:
        mostrar_amostras_dataset()
        return True
    else:
        print("Nenhuma imagem encontrada. Para usar o modelo:")
        print("   1. Adicione imagens em data/images/")
        print("   2. Adicione labels em data/labels/ (opcional)")
        print("   3. Ou use o modelo pr√©-treinado para demonstra√ß√£o")
        return False

# Verifica√ß√£o do dataset
tem_dados = verificar_dataset()

# Fun√ß√£o para baixar imagens de demonstra√ß√£o se n√£o houver dados
def baixar_dados_demonstracao():
    """Baixa imagens de demonstra√ß√£o se n√£o houver dados dispon√≠veis."""
    if tem_dados:
        print("Dados locais dispon√≠veis, pulando download.")
        return True
    
    print("\nüì• Tentando baixar imagens de demonstra√ß√£o...")
    
    try:
        import urllib.request
        import os
        
        # URLs de imagens de exemplo (pessoas com celulares)
        sample_urls = [
            "https://images.unsplash.com/photo-1511367461989-f85a21fda167?w=640&h=480&fit=crop",
            "https://images.unsplash.com/photo-1556157382-97eda2d62296?w=640&h=480&fit=crop", 
            "https://images.unsplash.com/photo-1526947425960-945c6e72858f?w=640&h=480&fit=crop",
            "https://images.unsplash.com/photo-1423784346385-c1d4dac9893a?w=640&h=480&fit=crop",
        ]
        
        download_count = 0
        
        for i, url in enumerate(sample_urls):
            try:
                filename = f"sample_{i+1}.jpg"
                filepath = os.path.join(images_path, filename)
                
                print(f"   Baixando {filename}...")
                # Timeout para evitar travamento
                urllib.request.urlretrieve(url, filepath)
                
                # Verificar se o arquivo foi baixado corretamente
                if os.path.exists(filepath) and os.path.getsize(filepath) > 1000:  # Pelo menos 1KB
                    download_count += 1
                    print(f"     {filename} baixado com sucesso")
                else:
                    print(f"     {filename} parece corrompido")
                    if os.path.exists(filepath):
                        os.remove(filepath)
                
            except Exception as e:
                print(f"     Erro ao baixar {filename}: {e}")
                continue
        
        if download_count > 0:
            print(f"  {download_count} imagens baixadas com sucesso!")
            print("  Verificando dataset novamente...")
            # Verificar novamente se agora temos dados
            global tem_dados
            tem_dados = verificar_dataset()
            return tem_dados
        else:
            print("  Nenhuma imagem foi baixada com sucesso.")
            return False
            
    except ImportError:
        print("  urllib n√£o dispon√≠vel - sem conex√£o com internet ou biblioteca n√£o instalada")
        return False
    except Exception as e:
        print(f"  Erro no download: {e}")
        return False

# Tentar baixar dados de demonstra√ß√£o se necess√°rio
if not tem_dados:
    print("\n  Nenhuma imagem encontrada localmente.")
    print("   Op√ß√µes dispon√≠veis:")
    print("   1. Baixar imagens de demonstra√ß√£o")
    print("   2. Criar imagem sint√©tica") 
    print("   3. Adicionar suas pr√≥prias imagens em data/images/")
    
    # Tentar baixar primeiro
    success = baixar_dados_demonstracao()
    
    # Se download falhou, criar imagens demo
    if not success:
        print("\n  Download n√£o funcionou. Criando imagens demo...")
        demo_images = criar_imagens_demo()
        if demo_images:
            print("  Imagens de demonstra√ß√£o criadas!")
        else:
            print("  N√£o foi poss√≠vel criar imagens demo.")
            print("  Adicione manualmente suas imagens em data/images/ para continuar")


print("Modelo YOLOv8 pronto para usar!")
print("Execute a se√ß√£o de testes para ver o modelo funcionando!")

"""# Abaixo algumas se√ß√µes de exemplo

> Pode haver mais, dependendo da sua aplica√ß√£o. Para cada se√ß√£o fa√ßa coment√°rios explicando a tarefa e comentando/sumarizando os resultados.

# **Prepara√ß√£o e transforma√ß√£o dos dados**
"""

# Prepara√ß√£o dos dados para YOLO
print("\nPreparando configura√ß√£o dos dados...")

# Cria√ß√£o do arquivo de configura√ß√£o do dataset
dataset_config = {
    'path': os.path.abspath('./data'),
    'train': 'images/train',
    'val': 'images/val',
    'test': 'images/test',
    'names': {
        0: 'person',
        67: 'cell phone',  # Classe original do COCO
        999: 'person_with_phone'  # Classe customizada
    }
}

# Cria√ß√£o do arquivo dataset.yaml
dataset_yaml_path = './data/dataset.yaml'
try:
    with open(dataset_yaml_path, 'w') as f:
        yaml.dump(dataset_config, f, default_flow_style=False)
    print(f"Configura√ß√£o salva em: {dataset_yaml_path}")
except Exception as e:
    print(f"Erro ao criar dataset.yaml: {e}")

# Fun√ß√£o para configurar aumento de dados (Data Augmentation)
def criar_configuracao_augmentation():
    """Cria configura√ß√£o para aumento de dados."""
    try:
        import albumentations as A

        transform = A.Compose([
            A.HorizontalFlip(p=0.5),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),
            A.Rotate(limit=15, p=0.3),
            A.Blur(blur_limit=3, p=0.1),
            A.GaussNoise(var_limit=10, p=0.1),
            A.RandomGamma(gamma_limit=(80, 120), p=0.2),
        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))

        print("Configura√ß√£o de Data Augmentation criada")
        return transform
    except ImportError:
        print("Albumentations n√£o dispon√≠vel. Data Augmentation b√°sico ser√° usado.")
        return None

# Configura√ß√£o de augmentation
augmentation_transform = criar_configuracao_augmentation()

# Divis√£o do dataset em treino/valida√ß√£o/teste se necess√°rio
def dividir_dataset():
    """Divide dataset em conjuntos de treino, valida√ß√£o e teste."""
    print("\nVerificando divis√£o do dataset...")

    # Verificar se j√° existe divis√£o
    train_path = os.path.join(images_path, 'train')
    val_path = os.path.join(images_path, 'val')
    test_path = os.path.join(images_path, 'test')

    train_exists = os.path.exists(train_path) and len(os.listdir(train_path)) > 0
    val_exists = os.path.exists(val_path) and len(os.listdir(val_path)) > 0
    test_exists = os.path.exists(test_path) and len(os.listdir(test_path)) > 0

    if train_exists and val_exists:
        print("Dataset j√° dividido em train/val/test")
        train_count = len([f for f in os.listdir(train_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
        val_count = len([f for f in os.listdir(val_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
        test_count = len([f for f in os.listdir(test_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]) if test_exists else 0

        print(f"  Treino: {train_count} imagens")
        print(f"  Valida√ß√£o: {val_count} imagens")
        print(f"  Teste: {test_count} imagens")

        return train_count, val_count, test_count

    # Se n√£o existe divis√£o, verificar se h√° imagens na pasta raiz
    root_images = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

    if len(root_images) > 0:
        print(f"Encontradas {len(root_images)} imagens na pasta raiz")
        print("Dividindo dataset automaticamente...")

        # Mover imagens para pastas apropriadas
        import shutil

        def mover_imagens_para_split(img_list, split_name):
            split_img_path = os.path.join(images_path, split_name)
            split_label_path = os.path.join(labels_path, split_name)

            for img_name in img_list:
                # Mover imagem
                src_img = os.path.join(images_path, img_name)
                dst_img = os.path.join(split_img_path, img_name)
                shutil.move(src_img, dst_img)

                # Mover label se existir
                label_name = os.path.splitext(img_name)[0] + '.txt'
                src_label = os.path.join(labels_path, label_name)
                if os.path.exists(src_label):
                    dst_label = os.path.join(split_label_path, label_name)
                    shutil.move(src_label, dst_label)

        try:
            # CORRE√á√ÉO: Verificar n√∫mero de imagens antes de usar train_test_split
            if len(root_images) == 1:
                print("Apenas 1 imagem encontrada - usando para teste")
                mover_imagens_para_split([root_images[0]], 'test')
                return 0, 0, 1
            elif len(root_images) == 2:
                print("Apenas 2 imagens encontradas - 1 para treino, 1 para teste")
                mover_imagens_para_split([root_images[0]], 'train')
                mover_imagens_para_split([root_images[1]], 'test')
                return 1, 0, 1
            elif len(root_images) < 5:
                print(f"Poucas imagens ({len(root_images)}) - dividindo manualmente")
                # Para 3-4 imagens: maioria para train, √∫ltima para test
                train_imgs = root_images[:-1]  # Todas exceto a √∫ltima
                test_imgs = [root_images[-1]]  # √öltima imagem
                
                mover_imagens_para_split(train_imgs, 'train')
                mover_imagens_para_split(test_imgs, 'test')
                
                print(f"Dataset dividido:")
                print(f"  Treino: {len(train_imgs)} imagens")
                print(f"  Valida√ß√£o: 0 imagens")
                print(f"  Teste: {len(test_imgs)} imagens")
                
                return len(train_imgs), 0, len(test_imgs)
            else:
                # Usar train_test_split apenas com 5+ imagens
                print("Suficientes imagens para divis√£o autom√°tica com sklearn")
                train_imgs, temp_imgs = train_test_split(root_images, test_size=0.3, random_state=42)
                val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)

                mover_imagens_para_split(train_imgs, 'train')
                mover_imagens_para_split(val_imgs, 'val')
                mover_imagens_para_split(test_imgs, 'test')

                print(f"Dataset dividido com sucesso:")
                print(f"  Treino: {len(train_imgs)} imagens")
                print(f"  Valida√ß√£o: {len(val_imgs)} imagens")
                print(f"  Teste: {len(test_imgs)} imagens")

                return len(train_imgs), len(val_imgs), len(test_imgs)

        except Exception as e:
            print(f"Erro ao dividir dataset: {e}")
            print("Continuando sem divis√£o - usando modelo pr√©-treinado")
            return 0, 0, 0
    else:
        print("Nenhuma imagem encontrada para dividir")
        return 0, 0, 0

# Executar divis√£o do dataset se necess√°rio
if tem_dados:
    train_count, val_count, test_count = dividir_dataset()
else:
    train_count, val_count, test_count = 0, 0, 0

"""# **Fine Tuning do modelo**

"""

print("\nConfigurando modelo YOLO...")

# Detectar dispositivo dispon√≠vel
def detectar_dispositivo():
    """Detecta o melhor dispositivo dispon√≠vel (GPU/CPU)."""
    try:
        import torch
        if torch.cuda.is_available():
            device = 'cuda'
            print(f"GPU detectada: {torch.cuda.get_device_name(0)}")
        else:
            device = 'cpu'
            print("GPU n√£o dispon√≠vel. Usando CPU.")
    except ImportError:
        device = 'cpu'
        print("PyTorch n√£o dispon√≠vel. Usando CPU por padr√£o.")

    return device

device = detectar_dispositivo()

# Configura√ß√µes de treinamento otimizadas para execu√ß√£o local
training_config = {
    'data': dataset_yaml_path,
    'epochs': 20,        # Reduzido para execu√ß√£o local mais r√°pida
    'imgsz': 640,
    'batch': 8 if device == 'cuda' else 4,  # Ajustar batch baseado no dispositivo
    'device': device,
    'workers': 4 if device == 'cuda' else 2,
    'patience': 10,
    'save_period': 5,    # Salvar checkpoint a cada 5 √©pocas
    'project': './models',
    'name': 'yolov8_pessoa_celular',
    'exist_ok': True,
    'pretrained': True,
    'optimizer': 'SGD',
    'lr0': 0.01,
    'momentum': 0.937,
    'weight_decay': 0.0005,
    'warmup_epochs': 3,
    'box': 7.5,
    'cls': 0.5,
    'dfl': 1.5,
    'pose': 12.0,
    'kobj': 1.0,
    'label_smoothing': 0.0,
    'nbs': 64,
    'hsv_h': 0.015,
    'hsv_s': 0.7,
    'hsv_v': 0.4,
    'degrees': 0.0,
    'translate': 0.1,
    'scale': 0.5,
    'shear': 0.0,
    'perspective': 0.0,
    'flipud': 0.0,
    'fliplr': 0.5,
    'mosaic': 1.0,
    'mixup': 0.0,
    'copy_paste': 0.0
}

# Verifica√ß√£o se modelo j√° existe
model_path = './models/yolov8_pessoa_celular/weights/best.pt'
backup_model_path = './models/best_model.pt'

def carregar_ou_criar_modelo():
    """Carrega modelo existente ou cria novo."""

    # Tentar carregar modelo treinado
    if os.path.exists(model_path):
        print(f"Modelo treinado encontrado: {model_path}")
        try:
            model = YOLO(model_path)
            print("Modelo carregado com sucesso!")
            return model, 'trained'
        except Exception as e:
            print(f"Erro ao carregar modelo: {e}")

    # Tentar backup
    if os.path.exists(backup_model_path):
        print(f"Modelo backup encontrado: {backup_model_path}")
        try:
            model = YOLO(backup_model_path)
            print("Modelo backup carregado!")
            return model, 'backup'
        except Exception as e:
            print(f"Erro ao carregar backup: {e}")

    # Usar modelo pr√©-treinado
    print("Carregando modelo pr√©-treinado YOLOv8...")
    try:
        model = YOLO('yolov8n.pt')  # Modelo nano, mais r√°pido para testes
        print("Modelo pr√©-treinado carregado!")
        return model, 'pretrained'
    except Exception as e:
        print(f"Erro ao carregar modelo pr√©-treinado: {e}")
        return None, 'error'

# Carregar modelo
try:
    model, model_status = carregar_ou_criar_modelo()
except Exception as e:
    print(f"ERRO CR√çTICO: N√£o foi poss√≠vel carregar modelo YOLO: {e}")
    print("Poss√≠veis solu√ß√µes:")
    print("  1. pip install ultralytics")
    print("  2. Verificar conex√£o com internet para download autom√°tico")
    print("  3. Verificar espa√ßo em disco")
    model, model_status = None, 'error'

def treinar_modelo():
    """Treina o modelo se houver dados dispon√≠veis."""
    if not model:
        print("  Nenhum modelo dispon√≠vel para treinamento")
        print("  Resolva primeiro os problemas de carregamento do modelo")
        return None

    if train_count == 0:
        print("Nenhum dado de treino dispon√≠vel. Pulando treinamento.")
        print("Para treinar o modelo:")
        print("   1. Adicione imagens em data/images/train/")
        print("   2. Adicione labels em data/labels/train/")
        print("   3. Execute novamente o treinamento")
        return model

    if not os.path.exists(dataset_yaml_path):
        print("Arquivo dataset.yaml n√£o encontrado. N√£o √© poss√≠vel treinar.")
        return model

    print(f"\nIniciando treinamento com {train_count} imagens...")
    print(f"Configura√ß√µes:")
    print(f"   - √âpocas: {training_config['epochs']}")
    print(f"   - Batch size: {training_config['batch']}")
    print(f"   - Dispositivo: {training_config['device']}")
    print(f"   - Workers: {training_config['workers']}")

    try:
        # Iniciar treinamento
        results = model.train(**training_config)

        # Salvar modelo treinado
        trained_model_path = './models/best_model.pt'
        model.save(trained_model_path)
        print(f"Modelo salvo em: {trained_model_path}")

        # Mostrar m√©tricas de treinamento
        if hasattr(results, 'results_dict'):
            print("\nResultados do Treinamento:")
            metrics = results.results_dict
            if 'metrics/mAP50(B)' in metrics:
                print(f"   - mAP50: {metrics['metrics/mAP50(B)']:.3f}")
            if 'metrics/mAP50-95(B)' in metrics:
                print(f"   - mAP50-95: {metrics['metrics/mAP50-95(B)']:.3f}")
            if 'metrics/precision(B)' in metrics:
                print(f"   - Precis√£o: {metrics['metrics/precision(B)']:.3f}")
            if 'metrics/recall(B)' in metrics:
                print(f"   - Recall: {metrics['metrics/recall(B)']:.3f}")

        return model

    except Exception as e:
        print(f"Erro durante o treinamento: {e}")
        print("Poss√≠veis solu√ß√µes:")
        print("   - Verificar se o dataset.yaml est√° correto")
        print("   - Reduzir batch_size se houver erro de mem√≥ria")
        print("   - Verificar se as imagens e labels est√£o nos diret√≥rios corretos")
        return model

# Op√ß√£o de treinamento
if model_status == 'pretrained' and train_count > 0 and model is not None:
    print("\nOp√ß√µes de treinamento:")
    print("   [1] Sim, treinar agora")
    print("   [2] N√£o, usar modelo pr√©-treinado")
    print("   [3] Treinar automaticamente (recomendado)")

    # Para execu√ß√£o autom√°tica em notebook, treinar se houver dados suficientes
    if train_count >= 10:  # M√≠nimo de 10 imagens para treinar
        print("Treinamento autom√°tico iniciado (dados suficientes detectados)")
        model = treinar_modelo()
    else:
        print(f"Poucos dados ({train_count} imagens). Recomenda-se pelo menos 10 imagens para treinar.")
        print("Continuando com modelo pr√©-treinado...")

elif model_status == 'pretrained' and model is not None:
    print("Usando modelo pr√©-treinado. Nenhum dado de treino dispon√≠vel.")
elif model is None:
    print(" Modelo n√£o carregado - pulando se√ß√£o de treinamento")

# Fun√ß√£o para visualizar m√©tricas de treinamento
def plotar_metricas_treinamento():
    """Plota m√©tricas de treinamento se dispon√≠veis."""
    try:
        results_path = './models/yolov8_pessoa_celular'
        if os.path.exists(results_path):
            # Tentar carregar e plotar resultados
            print("Visualizando m√©tricas de treinamento...")

            # Procurar por arquivos de resultados
            results_files = []
            for file in os.listdir(results_path):
                if file.endswith('.csv') or file.endswith('.png'):
                    results_files.append(file)

            if results_files:
                print(f"Encontrados arquivos de resultados: {results_files}")

                # Mostrar gr√°ficos se existirem
                for file in results_files:
                    if file.endswith('.png') and 'results' in file.lower():
                        img_path = os.path.join(results_path, file)
                        try:
                            img = plt.imread(img_path)
                            plt.figure(figsize=(12, 8))
                            plt.imshow(img)
                            plt.title(f'M√©tricas de Treinamento - {file}')
                            plt.axis('off')
                            plt.show()
                        except Exception as e:
                            print(f"Erro ao mostrar {file}: {e}")
            else:
                print("Nenhum arquivo de resultados encontrado")
        else:
            print("Diret√≥rio de resultados n√£o encontrado")

    except Exception as e:
        print(f"Erro ao plotar m√©tricas: {e}")

# Plotar m√©tricas se dispon√≠veis
if model_status in ['trained', 'backup']:
    plotar_metricas_treinamento()

"""# **Avalia√ß√£o do modelo**


"""

print("\nConfigurando avalia√ß√£o do modelo...")

def avaliar_modelo():
    """Avalia o modelo no conjunto de teste."""
    if not model:
        print("  Nenhum modelo dispon√≠vel para avalia√ß√£o")
        return None

    print("\nIniciando avalia√ß√£o do modelo...")

    try:
        # Avaliar no conjunto de valida√ß√£o/teste
        if os.path.exists(dataset_yaml_path) and val_count > 0:
            print(f"Avaliando com {val_count} imagens de valida√ß√£o...")
            test_results = model.val(data=dataset_yaml_path)

            # Exibir m√©tricas detalhadas
            print("\nM√©tricas de Avalia√ß√£o:")
            if hasattr(test_results, 'box'):
                box_metrics = test_results.box
                print(f"   mAP50: {box_metrics.map50:.3f}")
                print(f"   mAP50-95: {box_metrics.map:.3f}")
                print(f"   Precis√£o: {box_metrics.mp:.3f}")
                print(f"   Recall: {box_metrics.mr:.3f}")

                # M√©tricas por classe se dispon√≠vel
                if hasattr(box_metrics, 'ap_class_index') and len(box_metrics.ap_class_index) > 0:
                    print("\nM√©tricas por Classe:")
                    class_names = {0: 'person', 67: 'cell phone', 999: 'person_with_phone'}
                    for i, class_idx in enumerate(box_metrics.ap_class_index):
                        class_name = class_names.get(int(class_idx), f'classe_{class_idx}')
                        if i < len(box_metrics.ap):
                            print(f"   {class_name}: mAP50 = {box_metrics.ap[i]:.3f}")

            return test_results
        else:
            print("Dados de valida√ß√£o n√£o dispon√≠veis. Avalia√ß√£o b√°sica ser√° realizada.")
            return None

    except Exception as e:
        print(f"Erro durante avalia√ß√£o: {e}")
        return None

# Executar avalia√ß√£o
evaluation_results = avaliar_modelo()

# Fun√ß√£o para criar matriz de confus√£o
def criar_matriz_confusao():
    """Cria e exibe matriz de confus√£o se poss√≠vel."""
    try:
        if evaluation_results and hasattr(evaluation_results, 'confusion_matrix'):
            cm = evaluation_results.confusion_matrix
            if cm is not None:
                print("\nMatriz de Confus√£o:")
                plt.figure(figsize=(10, 8))
                plt.imshow(cm.matrix, cmap='Blues')
                plt.title('Matriz de Confus√£o')
                plt.colorbar()

                # Adicionar r√≥tulos se poss√≠vel
                classes = ['person', 'cell phone', 'person_with_phone']
                tick_marks = np.arange(len(classes))
                plt.xticks(tick_marks, classes, rotation=45)
                plt.yticks(tick_marks, classes)

                plt.ylabel('Classe Real')
                plt.xlabel('Classe Predita')
                plt.tight_layout()
                plt.show()
            else:
                print("Matriz de confus√£o n√£o dispon√≠vel")
        else:
            print("Dados insuficientes para matriz de confus√£o")
    except Exception as e:
        print(f"Erro ao criar matriz de confus√£o: {e}")

# Criar matriz de confus√£o se poss√≠vel
criar_matriz_confusao()

# Fun√ß√£o para testar em imagem individual
def testar_imagem_individual(image_path, show_result=True, save_result=False):
    """Testa o modelo em uma √∫nica imagem."""
    if not model:
        print("  Modelo n√£o dispon√≠vel")
        return None

    if not os.path.exists(image_path):
        print(f"  Imagem n√£o encontrada: {image_path}")
        return None

    try:
        print(f"Testando imagem: {os.path.basename(image_path)}")

        # Fazer predi√ß√£o
        results = model(image_path, conf=0.5)

        # Contar detec√ß√µes
        total_detections = 0
        people_count = 0
        phones_count = 0
        people_with_phones = 0

        for r in results:
            boxes = r.boxes
            if boxes is not None:
                total_detections = len(boxes)
                for box in boxes:
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])

                    if conf > 0.5:
                        if cls == 0:  # person
                            people_count += 1
                        elif cls == 67:  # cell phone
                            phones_count += 1
                        elif cls == 999:  # person_with_phone
                            people_with_phones += 1

        print(f"   Resultados:")
        print(f"      Pessoas: {people_count}")
        print(f"      Celulares: {phones_count}")
        print(f"      Pessoas com celular: {people_with_phones}")
        print(f"      Total detec√ß√µes: {total_detections}")

        # Mostrar resultado visualmente
        if show_result:
            for r in results:
                im_array = r.plot()
                # Converter BGR para RGB para matplotlib
                im_rgb = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)

                plt.figure(figsize=(12, 8))
                plt.imshow(im_rgb)
                plt.title(f'Detec√ß√µes - {os.path.basename(image_path)}')
                plt.axis('off')
                plt.show()

        # Salvar resultado se solicitado
        if save_result:
            output_path = f"./models/detection_result_{os.path.basename(image_path)}"
            for r in results:
                im_array = r.plot()
                cv2.imwrite(output_path, im_array)
                print(f"Resultado salvo em: {output_path}")

        return results

    except Exception as e:
        print(f"Erro ao testar imagem: {e}")
        return None

# Fun√ß√£o para testar em v√≠deo
def testar_video(video_path, output_path=None, max_frames=100):
    """Testa o modelo em v√≠deo com limite de frames."""
    if not model:
        print("Modelo n√£o dispon√≠vel")
        return

    if not os.path.exists(video_path):
        print(f"V√≠deo n√£o encontrado: {video_path}")
        return

    try:
        print(f"Processando v√≠deo: {os.path.basename(video_path)}")

        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        print(f"   Total frames: {total_frames}")
        print(f"   FPS: {fps:.1f}")
        print(f"   Processando m√°ximo {max_frames} frames para demonstra√ß√£o")

        # Configurar output se solicitado
        out = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

        frame_count = 0
        detection_stats = []

        while True:
            ret, frame = cap.read()
            if not ret or frame_count >= max_frames:
                break

            # Processar frame
            results = model(frame, conf=0.5, verbose=False)
            annotated_frame = results[0].plot()

            # Contar detec√ß√µes
            total_detections = len(results[0].boxes) if results[0].boxes is not None else 0
            detection_stats.append(total_detections)

            # Mostrar progresso
            if frame_count % 10 == 0:
                print(f"   Frame {frame_count}/{min(max_frames, total_frames)} - Detec√ß√µes: {total_detections}")

            # Salvar frame se output especificado
            if out:
                out.write(annotated_frame)

            frame_count += 1

        cap.release()
        if out:
            out.release()
            print(f"V√≠deo processado salvo em: {output_path}")

        # Estat√≠sticas finais
        if detection_stats:
            avg_detections = np.mean(detection_stats)
            max_detections = max(detection_stats)
            print(f"\nEstat√≠sticas do V√≠deo:")
            print(f"   Detec√ß√µes m√©dias por frame: {avg_detections:.1f}")
            print(f"   M√°ximo de detec√ß√µes em um frame: {max_detections}")
            print(f"   Frames processados: {frame_count}")

        cv2.destroyAllWindows()

    except Exception as e:
        print(f"Erro ao processar v√≠deo: {e}")

# Fun√ß√£o para criar imagens de demonstra√ß√£o
def criar_imagens_demo():
    """Cria imagens sint√©ticas para demonstra√ß√£o se n√£o houver dados."""
    print("  Criando imagens de demonstra√ß√£o sint√©ticas...")
    
    try:
        # Criar m√∫ltiplas imagens de demonstra√ß√£o
        demo_images = []
        
        for i in range(3):  # Criar 3 imagens de demo
            # Criar imagem sint√©tica
            demo_img = np.ones((480, 640, 3), dtype=np.uint8) * 255
            
            # Adicionar cor de fundo variada
            if i == 0:
                demo_img[:, :] = [240, 248, 255]  # Alice blue
            elif i == 1:
                demo_img[:, :] = [255, 248, 220]  # Cornsilk  
            else:
                demo_img[:, :] = [245, 245, 245]  # White smoke
            
            # Adicionar texto indicativo
            cv2.putText(demo_img, f'DEMO IMAGE {i+1}', (50, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 2)
            cv2.putText(demo_img, 'Para teste do modelo YOLO', (50, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 100, 100), 2)
            cv2.putText(demo_img, 'Adicione suas imagens em:', (50, 130),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            cv2.putText(demo_img, 'data/images/test/', (50, 160),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # Desenhar formas representativas com varia√ß√µes
            person_x = 200 + i * 80
            person_y = 200
            
            # Ret√¢ngulo representando pessoa
            cv2.rectangle(demo_img, (person_x, person_y), (person_x + 80, person_y + 150), (255, 0, 0), 2)
            cv2.putText(demo_img, 'pessoa', (person_x, person_y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
            
            # Ret√¢ngulo representando celular
            phone_x = person_x + 60
            phone_y = person_y + 50
            cv2.rectangle(demo_img, (phone_x, phone_y), (phone_x + 30, phone_y + 50), (0, 255, 0), 2)
            cv2.putText(demo_img, 'celular', (phone_x - 20, phone_y + 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
            
            # Adicionar c√≠rculo para indicar √°rea de interesse
            cv2.circle(demo_img, (person_x + 40, person_y + 75), 100, (0, 0, 255), 2)
            cv2.putText(demo_img, '√°rea de detec√ß√£o', (person_x - 30, person_y + 200), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            
            # Salvar imagem de demonstra√ß√£o
            demo_path = f'./data/images/demo_image_{i+1}.jpg'
            success = cv2.imwrite(demo_path, demo_img)
            
            if success:
                demo_images.append(demo_path)
                print(f"     {demo_path} criada")
            else:
                print(f"     Erro ao salvar {demo_path}")
        
        if demo_images:
            print(f"  {len(demo_images)} imagens de demonstra√ß√£o criadas com sucesso!")
            # Atualizar status global
            global tem_dados
            tem_dados = verificar_dataset()
            return demo_images
        else:
            print("  Nenhuma imagem de demonstra√ß√£o foi criada")
            return None
            
    except Exception as e:
        print(f"  Erro ao criar demonstra√ß√£o: {e}")
        return None

# Testar modelo com dados dispon√≠veis ou demonstra√ß√£o
print("\nTestando modelo...")

# Fun√ß√£o melhorada para encontrar imagens de teste
def encontrar_imagens_teste():
    """Encontra imagens para teste com prioridade para data/images/test."""
    test_images = []
    source_info = ""

    # PRIORIDADE 1: Imagens fornecidas pelo usu√°rio em data/images/test
    test_path = os.path.join(images_path, 'test')
    if os.path.exists(test_path):
        test_imgs = [os.path.join(test_path, f) for f in os.listdir(test_path)
                    if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
        if test_imgs:
            test_images = test_imgs
            source_info = f"  Usando {len(test_imgs)} imagens do diret√≥rio TEST: {test_path}"
            print(source_info)
            print("  Imagens encontradas:")
            for i, img in enumerate(test_imgs[:10], 1):  # Mostrar at√© 10 imagens
                print(f"   {i}. {os.path.basename(img)}")
            if len(test_imgs) > 10:
                print(f"   ... e mais {len(test_imgs) - 10} imagens")
            return test_images, source_info

    # PRIORIDADE 2: Imagens de valida√ß√£o (se test n√£o existe)
    if val_count > 0:
        val_path = os.path.join(images_path, 'val')
        val_imgs = [os.path.join(val_path, f) for f in os.listdir(val_path)
                   if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:5]
        if val_imgs:
            test_images = val_imgs
            source_info = f"  Usando {len(val_imgs)} imagens do diret√≥rio VAL: {val_path}"
            print(source_info)
            return test_images, source_info

    # PRIORIDADE 3: Imagens da pasta raiz data/images
    if tem_dados:
        root_imgs = [os.path.join(images_path, f) for f in os.listdir(images_path)
                    if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:5]
        if root_imgs:
            test_images = root_imgs
            source_info = f"  Usando {len(root_imgs)} imagens da pasta raiz: {images_path}"
            print(source_info)
            return test_images, source_info

    return test_images, source_info

# Procurar por imagens de teste
test_images, source_info = encontrar_imagens_teste()

# Fun√ß√£o para testar todas as imagens encontradas
def executar_testes_completos(images_list):
    """Executa testes completos em uma lista de imagens."""
    if not images_list:
        print("  Nenhuma imagem dispon√≠vel para teste!")
        return

    print(f"\n  EXECUTANDO TESTES EM {len(images_list)} IMAGENS")
    print("=" * 60)

    resultados_gerais = []

    for i, img_path in enumerate(images_list, 1):
        print(f"\n  TESTE {i}/{len(images_list)}: {os.path.basename(img_path)}")
        print("-" * 40)

        # Verificar se a imagem existe
        if not os.path.exists(img_path):
            print(f"  Imagem n√£o encontrada: {img_path}")
            continue

        # Testar imagem individual
        results = testar_imagem_individual(img_path, show_result=True, save_result=False)

        if results:
            # Coletar estat√≠sticas
            total_detections = 0
            people_count = 0
            phones_count = 0

            for r in results:
                boxes = r.boxes
                if boxes is not None:
                    total_detections = len(boxes)
                    for box in boxes:
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])

                        if conf > 0.5:
                            if cls == 0:  # person
                                people_count += 1
                            elif cls == 67:  # cell phone
                                phones_count += 1

            resultado = {
                'imagem': os.path.basename(img_path),
                'pessoas': people_count,
                'celulares': phones_count,
                'total_deteccoes': total_detections
            }
            resultados_gerais.append(resultado)

            print(f"  Teste conclu√≠do - P:{people_count} C:{phones_count} T:{total_detections}")
        else:
            print(f"  Falha no teste da imagem")

    # Resumo final dos testes
    if resultados_gerais:
        print(f"\n  RESUMO DOS TESTES")
        print("=" * 60)
        print(f"  Total de imagens testadas: {len(resultados_gerais)}")
        print(f"  Total de pessoas detectadas: {sum(r['pessoas'] for r in resultados_gerais)}")
        print(f"  Total de celulares detectados: {sum(r['celulares'] for r in resultados_gerais)}")
        print(f"  Total de detec√ß√µes: {sum(r['total_deteccoes'] for r in resultados_gerais)}")

        print(f"\n  DETALHES POR IMAGEM:")
        for r in resultados_gerais:
            print(f"     {r['imagem']}: {r['pessoas']}P, {r['celulares']}C, {r['total_deteccoes']}T")

# Executar testes se h√° imagens dispon√≠veis
if test_images:
    if model is not None:
        executar_testes_completos(test_images)
    else:
        print("  Modelo n√£o dispon√≠vel - n√£o √© poss√≠vel executar testes")
        print("  Resolva primeiro os problemas de carregamento do modelo")
else:
    print("Nenhuma imagem encontrada para teste!")
    print("\nCOMO ADICIONAR SUAS IMAGENS:")
    print("   1. Coloque suas imagens na pasta: data/images/test/")
    print("   2. Formatos suportados: .jpg, .png, .jpeg")
    print("   3. Execute novamente o notebook")
    print("\nCriando demonstra√ß√£o como alternativa...")

    # Criar demonstra√ß√£o
    demo_images = criar_imagens_demo()
    if demo_images and model is not None:
        print("Testando com imagens de demonstra√ß√£o:")
        for demo_path in demo_images:
            testar_imagem_individual(demo_path, show_result=True)
    elif demo_images and model is None:
        print("  Imagens criadas, mas modelo n√£o dispon√≠vel para teste")
    else:
        print("  N√£o foi poss√≠vel criar imagens de demonstra√ß√£o")

"""# **Consumo do modelo**"""

print("\n  Configurando consumo do modelo...")

# Importar classe do m√≥dulo utils se dispon√≠vel
def setup_detector_class():
    """Configura a classe de detec√ß√£o para uso."""
    try:
        from utils.detector import PersonPhoneDetector
        print("    Classe PersonPhoneDetector importada com sucesso!")

        # Criar inst√¢ncia para teste
        detector = PersonPhoneDetector(confidence_threshold=0.5)
        print("    Detector configurado e pronto para uso!")
        return detector

    except ImportError as e:
        print(f"    M√≥dulo utils.detector n√£o encontrado: {e}")
        print("    Criando classe b√°sica para demonstra√ß√£o...")
        return create_basic_detector()

def create_basic_detector():
    """Cria classe b√°sica de detec√ß√£o se o m√≥dulo n√£o existir."""
    class BasicPersonPhoneDetector:
        def __init__(self, model_path=None, confidence_threshold=0.5):
            if model_path and os.path.exists(model_path):
                self.model = YOLO(model_path)
            elif model:
                self.model = model
            else:
                self.model = YOLO('yolov8n.pt')

            self.confidence_threshold = confidence_threshold

        def detect(self, image_source):
            """Realiza detec√ß√£o na imagem/v√≠deo."""
            try:
                results = self.model(image_source, conf=self.confidence_threshold)
                return results
            except Exception as e:
                print(f"  Erro na detec√ß√£o: {e}")
                return None

        def count_detections(self, results):
            """Conta diferentes tipos de detec√ß√µes."""
            people_count = 0
            phones_count = 0
            people_with_phones = 0

            if not results:
                return people_count, phones_count, people_with_phones

            for r in results:
                boxes = r.boxes
                if boxes is not None:
                    for box in boxes:
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])

                        if conf > self.confidence_threshold:
                            if cls == 0:  # person
                                people_count += 1
                            elif cls == 67:  # cell phone
                                phones_count += 1
                            elif cls == 999:  # person_with_phone
                                people_with_phones += 1

            return people_count, phones_count, people_with_phones

        def analyze_image(self, image_path):
            """An√°lise completa de uma imagem."""
            results = self.detect(image_path)
            if results:
                people, phones, people_with_phones = self.count_detections(results)

                analysis = {
                    'image_path': image_path,
                    'total_detections': people + phones + people_with_phones,
                    'people': people,
                    'phones': phones,
                    'people_with_phones': people_with_phones,
                    'confidence_threshold': self.confidence_threshold
                }

                return analysis, results

            return None, None

    return BasicPersonPhoneDetector()

# Configurar detector
detector = setup_detector_class()

# Teste de funcionamento do detector
if detector and test_images:
    print("\n  Testando detector personalizado:")

    test_img = test_images[0] if test_images else None
    if test_img:
        try:
            analysis, results = detector.analyze_image(test_img)
            if analysis:
                print(f"    An√°lise completa da imagem:")
                print(f"       Imagem: {os.path.basename(analysis['image_path'])}")
                print(f"       Pessoas: {analysis['people']}")
                print(f"       Celulares: {analysis['phones']}")
                print(f"       Pessoas com celular: {analysis['people_with_phones']}")
                print(f"       Total: {analysis['total_detections']} detec√ß√µes")
                print(f"       Confian√ßa m√≠nima: {analysis['confidence_threshold']}")
        except Exception as e:
            print(f"    Erro no teste: {e}")

# Fun√ß√£o para executar aplica√ß√£o Streamlit (app.py)
def executar_aplicacao_streamlit():
    """Executa a aplica√ß√£o Streamlit principal (app.py)."""
    if os.path.exists('app.py'):
        print("\n  EXECUTANDO APLICA√á√ÉO STREAMLIT")
        print("="*50)
        print("  Usando app.py principal")
        print("  A aplica√ß√£o ser√° aberta automaticamente no navegador")
        print("  Para parar: Ctrl+C no terminal")
        print("="*50)

        try:
            subprocess.run([sys.executable, "-m", "streamlit", "run", "app.py"], check=True)
        except subprocess.CalledProcessError as e:
            print(f"  Erro ao executar app.py: {e}")
            print("  Verifique se o Streamlit est√° instalado: pip install streamlit")
        except Exception as e:
            print(f"  Erro inesperado: {e}")
    else:
        print("  Arquivo app.py n√£o encontrado!")
        print("  Certifique-se de que o app.py est√° no mesmo diret√≥rio")

print("="*60)

"""# **Refer√™ncias**

Este √© um item obrigat√≥rio. Inclua aqui o as refer√™ncias, fontes, ou bibliografia e sites/bibliotecas que foram empregados para construir a sua proposta.

# **Refer√™ncias**

1. Redmon, J., et al. "You Only Look Once: Unified, Real-Time Object Detection" (2016)
2. Ultralytics YOLOv8 Documentation: https://docs.ultralytics.com/
3. COCO Dataset: https://cocodataset.org/
4. Roboflow Documentation: https://docs.roboflow.com/
5. OpenCV Documentation: https://docs.opencv.org/
6. PyTorch Documentation: https://pytorch.org/docs/
7. Streamlit Documentation: https://docs.streamlit.io/
8. "Real-time Object Detection with YOLO" - Various academic papers
9. "Computer Vision: Algorithms and Applications" - Richard Szeliski
10. "Deep Learning for Computer Vision" - Adrian Rosebrock
11. Bochkovskiy, A., Wang, C. Y., & Liao, H. Y. M. (2020). "YOLOv4: Optimal Speed and Accuracy of Object Detection"
12. Wang, C. Y., Bochkovskiy, A., & Liao, H. Y. M. (2023). "YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors"
13. Jocher, G., Chaurasia, A., & Qiu, J. (2023). "YOLO by Ultralytics" (Version 8.0.0)
14. Lin, T. Y., et al. (2014). "Microsoft COCO: Common objects in context"
15. He, K., Zhang, X., Ren, S., & Sun, J. (2016). "Deep residual learning for image recognition"

---
"""

#@title **Avalia√ß√£o**
GitHub = 10 #@param {type:"slider", min:0, max:10, step:1}

Implementacao_Model_Code = 7 #@param {type:"slider", min:0, max:10, step:1}

Aplicacao_Streamlit = 9 #@param {type:"slider", min:0, max:10, step:1}

Texto_Artigo  = 6 #@param {type:"slider", min:0, max:10, step:1}

Video = 7 #@param {type:"slider", min:0, max:10, step:1}

Geral = 7 #@param {type:"slider", min:0, max:10, step:1}

#@title **Nota Final**

nota = 2*GitHub + 4*Implementacao_Model_Code + 2*Aplicacao_Streamlit + 1*Texto_Artigo + 1*Video

nota = nota / 10

print(f'Nota final do trabalho {nota :.1f}')

import numpy as np
import pandas as pd

alunos = pd.DataFrame()

lista_tia = []
lista_nome = []

for i in range(1,6):
  exec("if Aluno" + str(i) + " !='None':  lista = Aluno" + str(i) + ".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())")

alunos['tia'] = lista_tia
alunos['nome'] = lista_nome
alunos['nota'] = np.round(nota,1)
print()
display(alunos)