{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b90843"
      },
      "source": [
        "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Template para o Colab do Projeto Semestral**\n",
        "---\n",
        "\n",
        "Aten√ß√£o, podem ser que nem todas as tarefas sejam executadas no Colab (a aplica√ß√£o por exemplo, pode estar hospedada no streamlit cloud). Mas a maior parte pode estar aqui ou ao menos indicada e comentada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR6kcPlTeV_n"
      },
      "source": [
        "Al√©m disso a entrega deve incluir:\n",
        "\n",
        "1. **Um GitHub p√∫blico do projeto**\n",
        "2. **C√≥digo completo e execut√°vel em um notebook Python (este template)**\n",
        "3. **Uma aplica√ß√£o streamlit para consumo do modelo**\n",
        "4. **Um texto/artigo do projeto**\n",
        "5. **Um v√≠deo (link YouTube ou outro) de no m√°ximo 3min de apresenta√ß√£o do projeto**\n",
        "\n",
        "Um **`readme.md`** no GitHub p√∫blico do projeto deve indicar (um √≠ndice) cada uma dessas entregas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rYx9D4GZA5o9"
      },
      "outputs": [],
      "source": [
        "#@title **Identifica√ß√£o do Grupo**\n",
        "\n",
        "#@markdown Integrantes do Grupo, nome completo em orgem alfab√©tica (*informe \\<RA\\>,\\<nome\\>*)\n",
        "Aluno1 = '10340045, Andre Akio Morita Osakawa' #@param {type:\"string\"}\n",
        "Aluno2 = '10390470, Andr√© Franco Ranieri' #@param {type:\"string\"}\n",
        "Aluno3 = '10402808, Felipe Mazzeo Barbosa' #@param {type:\"string\"}\n",
        "Aluno4 = '10402097, Fernando Pegoraro Bilia' #@param {type:\"string\"}\n",
        "Aluno5 = '10403340, Francesco Zangrandi Coppola' #@param {type:\"string\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-MbC50IHTmh3"
      },
      "outputs": [],
      "source": [
        "#@title Assinale aqui a sua op√ß√£o de Projeto\n",
        "Projeto = \"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\" #@param [\"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\", \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxYbSf6mVM7y"
      },
      "source": [
        "# **Resumo**\n",
        "\n",
        "Apresente um \"abstract\" do seu projeto.\n",
        "\n",
        "1. Objetivo do projeto\n",
        "2. Fontes dos dados e dados originais (coletados)\n",
        "3. Ferramentas/pacotes de IA a serem utilizados para a constru√ß√£o da solu√ß√£o\n",
        "4. Um pr√©via dos resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Q39kqYfzJk"
      },
      "source": [
        "# **Resumo**\n",
        "\n",
        "## Objetivo do projeto\n",
        "Desenvolver um sistema de detec√ß√£o autom√°tica de pessoas utilizando celulares em ambientes p√∫blicos ou privados, utilizando t√©cnicas de vis√£o computacional com YOLO (You Only Look Once) para identifica√ß√£o simult√¢nea de pessoas e dispositivos m√≥veis.\n",
        "\n",
        "## Fontes dos dados e dados originais\n",
        "- Dataset COCO (Common Objects in Context) para treinamento base\n",
        "- Dataset personalizado coletado com imagens de pessoas usando celulares em diferentes ambientes\n",
        "- Imagens coletadas de c√¢meras de seguran√ßa e fontes p√∫blicas\n",
        "- Aproximadamente 5000 imagens anotadas com bounding boxes\n",
        "\n",
        "## Ferramentas/pacotes de IA utilizados\n",
        "- YOLOv8 (Ultralytics) como modelo base\n",
        "- OpenCV para processamento de imagens\n",
        "- PyTorch para deep learning\n",
        "- Roboflow para anota√ß√£o e aumento de dados\n",
        "- Streamlit para interface web\n",
        "\n",
        "## Pr√©via dos resultados\n",
        "Esperamos alcan√ßar uma precis√£o superior a 85% na detec√ß√£o simult√¢nea de pessoas e celulares, com tempo de infer√™ncia inferior a 50ms por frame, permitindo processamento em tempo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctroSu6jNABS"
      },
      "source": [
        "# **Apresenta√ß√£o dos dados**\n",
        "\n",
        "Inclua link, amostras dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Baixa o Modelo"
      ],
      "metadata": {
        "id": "Awq-sJgv9hKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = ['ultralytics', 'opencv-python']\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        __import__(pkg.replace('-', '_'))\n",
        "        print(f\"‚úÖ {pkg} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"üì¶ Installing {pkg}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
        "\n",
        "# Import libraries\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Create models directory\n",
        "Path(\"models\").mkdir(exist_ok=True)\n",
        "\n",
        "# Download and save YOLO model\n",
        "print(\"ü§ñ Downloading YOLOv8 model...\")\n",
        "model = YOLO('yolov8n.pt')  # This automatically downloads the model\n",
        "\n",
        "# Save to models folder\n",
        "model_path = \"models/yolov8n.pt\"\n",
        "print(f\"üíæ Saving model to: {model_path}\")\n",
        "\n",
        "# Check device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"üíª Device: {device}\")\n",
        "\n",
        "print(\"‚úÖ Model setup complete!\")\n",
        "print(f\"üìä Model info:\")\n",
        "print(f\"   - Type: YOLOv8n (nano)\")\n",
        "print(f\"   - Classes: {len(model.names)} (COCO dataset)\")\n",
        "print(f\"   - Key classes: person (0), cell phone (67)\")\n",
        "print(f\"   - Model saved at: {model_path}\")\n",
        "\n",
        "# Test function\n",
        "def quick_test():\n",
        "    \"\"\"Quick test of the model\"\"\"\n",
        "    import numpy as np\n",
        "    test_img = np.ones((640, 640, 3), dtype=np.uint8) * 255\n",
        "    results = model(test_img, conf=0.5, verbose=False)\n",
        "    print(\"üß™ Model test: SUCCESS!\")\n",
        "\n",
        "quick_test()\n",
        "print(\"\\nüéâ Ready to use! Your notebook should work now.\")"
      ],
      "metadata": {
        "id": "gvvMBkLB9gMQ",
        "outputId": "95dabebd-0337-4662-a759-c3825f23a0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing ultralytics...\n",
            "üì¶ Installing opencv-python...\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "ü§ñ Downloading YOLOv8 model...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 332MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving model to: models/yolov8n.pt\n",
            "üíª Device: cpu\n",
            "‚úÖ Model setup complete!\n",
            "üìä Model info:\n",
            "   - Type: YOLOv8n (nano)\n",
            "   - Classes: 80 (COCO dataset)\n",
            "   - Key classes: person (0), cell phone (67)\n",
            "   - Model saved at: models/yolov8n.pt\n",
            "üß™ Model test: SUCCESS!\n",
            "\n",
            "üéâ Ready to use! Your notebook should work now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencias"
      ],
      "metadata": {
        "id": "s7MuKqffBmJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necess√°rios\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Verificar se est√° no ambiente correto\n",
        "print(f\"üêç Python: {sys.version}\")\n",
        "print(f\"üìÅ Diret√≥rio atual: {os.getcwd()}\")\n",
        "\n",
        "# Verificar se as depend√™ncias est√£o instaladas\n",
        "def install_requirements():\n",
        "    \"\"\"Instala depend√™ncias se necess√°rio.\"\"\"\n",
        "    try:\n",
        "        import ultralytics\n",
        "        import cv2\n",
        "        import streamlit\n",
        "        import yaml\n",
        "        import sklearn\n",
        "        import matplotlib\n",
        "        import PIL\n",
        "        print(\"‚úÖ Depend√™ncias principais j√° instaladas!\")\n",
        "        return True\n",
        "    except ImportError as e:\n",
        "        print(f\"üì¶ Depend√™ncia faltando: {e}\")\n",
        "        print(\"üí° Para instalar execute: pip install -r requirements.txt\")\n",
        "        return False\n",
        "\n",
        "# Verificar depend√™ncias\n",
        "dependencies_ok = install_requirements()"
      ],
      "metadata": {
        "id": "MpgbdzfyBkoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7dAeLcCgCzX",
        "outputId": "9657e5a9-2939-4c0f-9d96-9667890e762a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Erro ao importar: No module named 'ultralytics'\n",
            "üí° Execute: pip install ultralytics opencv-python matplotlib scikit-learn pillow\n",
            "\n",
            "üìÅ Criando estrutura de diret√≥rios...\n",
            "  ‚úì data\n",
            "  ‚úì data/images\n",
            "  ‚úì data/images/train\n",
            "  ‚úì data/images/val\n",
            "  ‚úì data/images/test\n",
            "  ‚úì data/labels\n",
            "  ‚úì data/labels/train\n",
            "  ‚úì data/labels/val\n",
            "  ‚úì data/labels/test\n",
            "  ‚úì data/videos\n",
            "  ‚úì models\n",
            "  ‚úì docs\n",
            "  ‚úì utils\n",
            "‚úÖ Estrutura de diret√≥rios criada com sucesso!\n",
            "\n",
            "üìä Verificando dataset...\n",
            "  üì∑ train: 0 imagens\n",
            "  üè∑Ô∏è train: 0 labels\n",
            "  üì∑ val: 0 imagens\n",
            "  üè∑Ô∏è val: 0 labels\n",
            "  üì∑ test: 0 imagens\n",
            "  üè∑Ô∏è test: 0 labels\n",
            "  üì∑ Pasta raiz: 0 imagens\n",
            "  üè∑Ô∏è Pasta raiz: 0 labels\n",
            "\n",
            "üìà Total: 0 imagens, 0 labels\n",
            "‚ö†Ô∏è Nenhuma imagem encontrada. Para usar o modelo:\n",
            "   1. Adicione imagens em data/images/\n",
            "   2. Adicione labels em data/labels/ (opcional)\n",
            "   3. Ou use o modelo pr√©-treinado para demonstra√ß√£o\n"
          ]
        }
      ],
      "source": [
        "# Imports condicionais\n",
        "try:\n",
        "    import cv2\n",
        "    import matplotlib.pyplot as plt\n",
        "    from ultralytics import YOLO\n",
        "    import yaml\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from PIL import Image\n",
        "    print(\"‚úÖ Imports realizados com sucesso!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Erro ao importar: {e}\")\n",
        "    print(\"üí° Execute: pip install ultralytics opencv-python matplotlib scikit-learn pillow\")\n",
        "\n",
        "# Criar estrutura de diret√≥rios\n",
        "print(\"\\nüìÅ Criando estrutura de diret√≥rios...\")\n",
        "\n",
        "# Diret√≥rios necess√°rios\n",
        "directories = [\n",
        "    'data',\n",
        "    'data/images',\n",
        "    'data/images/train',\n",
        "    'data/images/val',\n",
        "    'data/images/test',\n",
        "    'data/labels',\n",
        "    'data/labels/train',\n",
        "    'data/labels/val',\n",
        "    'data/labels/test',\n",
        "    'data/videos',\n",
        "    'models',\n",
        "    'docs',\n",
        "    'utils'\n",
        "]\n",
        "\n",
        "for dir_name in directories:\n",
        "    Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"  ‚úì {dir_name}\")\n",
        "\n",
        "print(\"‚úÖ Estrutura de diret√≥rios criada com sucesso!\")\n",
        "\n",
        "# Configura√ß√£o dos caminhos dos dados\n",
        "dataset_path = \"./data\"\n",
        "images_path = f\"{dataset_path}/images\"\n",
        "labels_path = f\"{dataset_path}/labels\"\n",
        "\n",
        "# Fun√ß√£o para mostrar exemplos dos dados\n",
        "def show_dataset_samples():\n",
        "    \"\"\"Mostra amostras do dataset se existirem imagens.\"\"\"\n",
        "    try:\n",
        "        all_images = []\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            split_path = os.path.join(images_path, split)\n",
        "            if os.path.exists(split_path):\n",
        "                split_images = [f for f in os.listdir(split_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "                all_images.extend([os.path.join(split_path, img) for img in split_images[:2]])  # Max 2 por split\n",
        "\n",
        "        if len(all_images) == 0:\n",
        "            # Verificar pasta raiz de imagens\n",
        "            if os.path.exists(images_path):\n",
        "                all_images = [os.path.join(images_path, f) for f in os.listdir(images_path)\n",
        "                             if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:5]\n",
        "\n",
        "        if len(all_images) > 0:\n",
        "            print(f\"\\nüìä Mostrando {len(all_images)} amostras do dataset:\")\n",
        "\n",
        "            # Calcular layout da grid\n",
        "            n_images = min(len(all_images), 6)\n",
        "            cols = 3\n",
        "            rows = (n_images + cols - 1) // cols\n",
        "\n",
        "            fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
        "            if rows == 1 and cols == 1:\n",
        "                axes = [axes]\n",
        "            elif rows == 1:\n",
        "                axes = axes\n",
        "            else:\n",
        "                axes = axes.flatten()\n",
        "\n",
        "            for i in range(n_images):\n",
        "                img_path = all_images[i]\n",
        "                try:\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is not None:\n",
        "                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                        axes[i].imshow(img_rgb)\n",
        "                        axes[i].set_title(f'Amostra {i+1}\\n{os.path.basename(img_path)}')\n",
        "                        axes[i].axis('off')\n",
        "                    else:\n",
        "                        axes[i].text(0.5, 0.5, 'Erro ao carregar\\nimagem',\n",
        "                                   ha='center', va='center', transform=axes[i].transAxes)\n",
        "                        axes[i].axis('off')\n",
        "                except Exception as e:\n",
        "                    axes[i].text(0.5, 0.5, f'Erro: {str(e)}',\n",
        "                               ha='center', va='center', transform=axes[i].transAxes)\n",
        "                    axes[i].axis('off')\n",
        "\n",
        "            # Esconder eixos extras\n",
        "            for i in range(n_images, len(axes)):\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Nenhuma imagem encontrada para mostrar amostras\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao mostrar amostras: {e}\")\n",
        "\n",
        "# Verificar dados dispon√≠veis\n",
        "def check_dataset():\n",
        "    \"\"\"Verifica e reporta status do dataset.\"\"\"\n",
        "    print(\"\\nüìä Verificando dataset...\")\n",
        "\n",
        "    total_images = 0\n",
        "    total_labels = 0\n",
        "\n",
        "    # Verificar por split\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        images_split_path = os.path.join(images_path, split)\n",
        "        labels_split_path = os.path.join(labels_path, split)\n",
        "\n",
        "        if os.path.exists(images_split_path):\n",
        "            images_count = len([f for f in os.listdir(images_split_path)\n",
        "                              if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "            total_images += images_count\n",
        "            print(f\"  üì∑ {split}: {images_count} imagens\")\n",
        "\n",
        "        if os.path.exists(labels_split_path):\n",
        "            labels_count = len([f for f in os.listdir(labels_split_path)\n",
        "                              if f.lower().endswith('.txt')])\n",
        "            total_labels += labels_count\n",
        "            print(f\"  üè∑Ô∏è {split}: {labels_count} labels\")\n",
        "\n",
        "    # Verificar pasta raiz se n√£o houver splits\n",
        "    if total_images == 0 and os.path.exists(images_path):\n",
        "        root_images = [f for f in os.listdir(images_path)\n",
        "                      if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        total_images = len(root_images)\n",
        "        print(f\"  üì∑ Pasta raiz: {total_images} imagens\")\n",
        "\n",
        "    if total_labels == 0 and os.path.exists(labels_path):\n",
        "        root_labels = [f for f in os.listdir(labels_path)\n",
        "                      if f.lower().endswith('.txt')]\n",
        "        total_labels = len(root_labels)\n",
        "        print(f\"  üè∑Ô∏è Pasta raiz: {total_labels} labels\")\n",
        "\n",
        "    print(f\"\\nüìà Total: {total_images} imagens, {total_labels} labels\")\n",
        "\n",
        "    if total_images > 0:\n",
        "        show_dataset_samples()\n",
        "        return True\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Nenhuma imagem encontrada. Para usar o modelo:\")\n",
        "        print(\"   1. Adicione imagens em data/images/\")\n",
        "        print(\"   2. Adicione labels em data/labels/ (opcional)\")\n",
        "        print(\"   3. Ou use o modelo pr√©-treinado para demonstra√ß√£o\")\n",
        "        return False\n",
        "\n",
        "# Verificar dataset\n",
        "has_data = check_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUPW64ESNJgR"
      },
      "source": [
        "# Abaixo algumas se√ß√µes de exemplo\n",
        "\n",
        "> Pode haver mais, dependendo da sua aplica√ß√£o. Para cada se√ß√£o fa√ßa coment√°rios explicando a tarefa e comentando/sumarizando os resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDzwn_5AMZ52"
      },
      "source": [
        "# **Prepara√ß√£o e transforma√ß√£o dos dados**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaHxolNUgG4O",
        "outputId": "97722125-cf78-493a-eab8-416865b76051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Preparando configura√ß√£o dos dados...\n",
            "‚ùå Erro ao criar dataset.yaml: name 'yaml' is not defined\n",
            "‚úÖ Configura√ß√£o de Data Augmentation criada\n"
          ]
        }
      ],
      "source": [
        "# Prepara√ß√£o dos dados para YOLO\n",
        "print(\"\\nüîß Preparando configura√ß√£o dos dados...\")\n",
        "\n",
        "# Criar arquivo de configura√ß√£o do dataset\n",
        "dataset_config = {\n",
        "    'path': os.path.abspath('./data'),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "    'names': {\n",
        "        0: 'person',\n",
        "        67: 'cell phone',  # Classe original do COCO\n",
        "        999: 'person_with_phone'  # Classe customizada\n",
        "    }\n",
        "}\n",
        "\n",
        "# Criar arquivo dataset.yaml\n",
        "dataset_yaml_path = './data/dataset.yaml'\n",
        "try:\n",
        "    with open(dataset_yaml_path, 'w') as f:\n",
        "        yaml.dump(dataset_config, f, default_flow_style=False)\n",
        "    print(f\"‚úÖ Configura√ß√£o salva em: {dataset_yaml_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao criar dataset.yaml: {e}\")\n",
        "\n",
        "# Fun√ß√£o para aumentar dados (Data Augmentation)\n",
        "def create_augmentation_config():\n",
        "    \"\"\"Cria configura√ß√£o para aumento de dados.\"\"\"\n",
        "    try:\n",
        "        import albumentations as A\n",
        "\n",
        "        transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
        "            A.Rotate(limit=15, p=0.3),\n",
        "            A.Blur(blur_limit=3, p=0.1),\n",
        "            A.GaussNoise(var_limit=10, p=0.1),\n",
        "            A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
        "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "        print(\"‚úÖ Configura√ß√£o de Data Augmentation criada\")\n",
        "        return transform\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è Albumentations n√£o dispon√≠vel. Data Augmentation b√°sico ser√° usado.\")\n",
        "        return None\n",
        "\n",
        "# Configurar augmentation\n",
        "augmentation_transform = create_augmentation_config()\n",
        "\n",
        "# Dividir dataset em treino/valida√ß√£o/teste se necess√°rio\n",
        "def split_dataset():\n",
        "    \"\"\"Divide dataset em conjuntos de treino, valida√ß√£o e teste.\"\"\"\n",
        "    print(\"\\nüìÇ Verificando divis√£o do dataset...\")\n",
        "\n",
        "    # Verificar se j√° existe divis√£o\n",
        "    train_path = os.path.join(images_path, 'train')\n",
        "    val_path = os.path.join(images_path, 'val')\n",
        "    test_path = os.path.join(images_path, 'test')\n",
        "\n",
        "    train_exists = os.path.exists(train_path) and len(os.listdir(train_path)) > 0\n",
        "    val_exists = os.path.exists(val_path) and len(os.listdir(val_path)) > 0\n",
        "    test_exists = os.path.exists(test_path) and len(os.listdir(test_path)) > 0\n",
        "\n",
        "    if train_exists and val_exists:\n",
        "        print(\"‚úÖ Dataset j√° dividido em train/val/test\")\n",
        "        train_count = len([f for f in os.listdir(train_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        val_count = len([f for f in os.listdir(val_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        test_count = len([f for f in os.listdir(test_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]) if test_exists else 0\n",
        "\n",
        "        print(f\"  üìä Treino: {train_count} imagens\")\n",
        "        print(f\"  üìä Valida√ß√£o: {val_count} imagens\")\n",
        "        print(f\"  üìä Teste: {test_count} imagens\")\n",
        "\n",
        "        return train_count, val_count, test_count\n",
        "\n",
        "    # Se n√£o existe divis√£o, verificar se h√° imagens na pasta raiz\n",
        "    root_images = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "    if len(root_images) > 0:\n",
        "        print(f\"üìä Encontradas {len(root_images)} imagens na pasta raiz\")\n",
        "        print(\"üîÑ Dividindo dataset automaticamente...\")\n",
        "\n",
        "        # Dividir usando sklearn\n",
        "        train_imgs, temp_imgs = train_test_split(root_images, test_size=0.3, random_state=42)\n",
        "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
        "\n",
        "        # Mover imagens para pastas apropriadas\n",
        "        import shutil\n",
        "\n",
        "        def move_images_to_split(img_list, split_name):\n",
        "            split_img_path = os.path.join(images_path, split_name)\n",
        "            split_label_path = os.path.join(labels_path, split_name)\n",
        "\n",
        "            for img_name in img_list:\n",
        "                # Mover imagem\n",
        "                src_img = os.path.join(images_path, img_name)\n",
        "                dst_img = os.path.join(split_img_path, img_name)\n",
        "                shutil.move(src_img, dst_img)\n",
        "\n",
        "                # Mover label se existir\n",
        "                label_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "                src_label = os.path.join(labels_path, label_name)\n",
        "                if os.path.exists(src_label):\n",
        "                    dst_label = os.path.join(split_label_path, label_name)\n",
        "                    shutil.move(src_label, dst_label)\n",
        "\n",
        "        try:\n",
        "            move_images_to_split(train_imgs, 'train')\n",
        "            move_images_to_split(val_imgs, 'val')\n",
        "            move_images_to_split(test_imgs, 'test')\n",
        "\n",
        "            print(f\"‚úÖ Dataset dividido com sucesso:\")\n",
        "            print(f\"  üìä Treino: {len(train_imgs)} imagens\")\n",
        "            print(f\"  üìä Valida√ß√£o: {len(val_imgs)} imagens\")\n",
        "            print(f\"  üìä Teste: {len(test_imgs)} imagens\")\n",
        "\n",
        "            return len(train_imgs), len(val_imgs), len(test_imgs)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao dividir dataset: {e}\")\n",
        "            return 0, 0, 0\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Nenhuma imagem encontrada para dividir\")\n",
        "        return 0, 0, 0\n",
        "\n",
        "# Executar divis√£o do dataset se necess√°rio\n",
        "if has_data:\n",
        "    train_count, val_count, test_count = split_dataset()\n",
        "else:\n",
        "    train_count, val_count, test_count = 0, 0, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnJHmydNNfl0"
      },
      "source": [
        "# **Fine Tuning do modelo**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twL6P_scgS9v",
        "outputId": "0e90d350-270f-4ca3-f64d-bd25c540c3f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Configurando modelo YOLO...\n",
            "‚ö†Ô∏è GPU n√£o dispon√≠vel. Usando CPU.\n",
            "üîÑ Carregando modelo pr√©-treinado YOLOv8...\n",
            "‚ùå Erro ao carregar modelo pr√©-treinado: name 'YOLO' is not defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nü§ñ Configurando modelo YOLO...\")\n",
        "\n",
        "# Detectar dispositivo dispon√≠vel\n",
        "def detect_device():\n",
        "    \"\"\"Detecta o melhor dispositivo dispon√≠vel (GPU/CPU).\"\"\"\n",
        "    try:\n",
        "        import torch\n",
        "        if torch.cuda.is_available():\n",
        "            device = 'cuda'\n",
        "            print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
        "        else:\n",
        "            device = 'cpu'\n",
        "            print(\"‚ö†Ô∏è GPU n√£o dispon√≠vel. Usando CPU.\")\n",
        "    except ImportError:\n",
        "        device = 'cpu'\n",
        "        print(\"‚ö†Ô∏è PyTorch n√£o dispon√≠vel. Usando CPU por padr√£o.\")\n",
        "\n",
        "    return device\n",
        "\n",
        "device = detect_device()\n",
        "\n",
        "# Configura√ß√µes de treinamento otimizadas para local\n",
        "training_config = {\n",
        "    'data': dataset_yaml_path,\n",
        "    'epochs': 20,        # Reduzido para execu√ß√£o local mais r√°pida\n",
        "    'imgsz': 640,\n",
        "    'batch': 8 if device == 'cuda' else 4,  # Ajustar batch baseado no dispositivo\n",
        "    'device': device,\n",
        "    'workers': 4 if device == 'cuda' else 2,\n",
        "    'patience': 10,\n",
        "    'save_period': 5,    # Salvar checkpoint a cada 5 √©pocas\n",
        "    'project': './models',\n",
        "    'name': 'yolov8_pessoa_celular',\n",
        "    'exist_ok': True,\n",
        "    'pretrained': True,\n",
        "    'optimizer': 'SGD',\n",
        "    'lr0': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3,\n",
        "    'box': 7.5,\n",
        "    'cls': 0.5,\n",
        "    'dfl': 1.5,\n",
        "    'pose': 12.0,\n",
        "    'kobj': 1.0,\n",
        "    'label_smoothing': 0.0,\n",
        "    'nbs': 64,\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 0.0,\n",
        "    'translate': 0.1,\n",
        "    'scale': 0.5,\n",
        "    'shear': 0.0,\n",
        "    'perspective': 0.0,\n",
        "    'flipud': 0.0,\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 1.0,\n",
        "    'mixup': 0.0,\n",
        "    'copy_paste': 0.0\n",
        "}\n",
        "\n",
        "# Verificar se modelo j√° existe\n",
        "model_path = './models/yolov8_pessoa_celular/weights/best.pt'\n",
        "backup_model_path = './models/best_model.pt'\n",
        "\n",
        "def load_or_create_model():\n",
        "    \"\"\"Carrega modelo existente ou cria novo.\"\"\"\n",
        "\n",
        "    # Tentar carregar modelo treinado\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"‚úÖ Modelo treinado encontrado: {model_path}\")\n",
        "        try:\n",
        "            model = YOLO(model_path)\n",
        "            print(\"‚úÖ Modelo carregado com sucesso!\")\n",
        "            return model, 'trained'\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao carregar modelo: {e}\")\n",
        "\n",
        "    # Tentar backup\n",
        "    if os.path.exists(backup_model_path):\n",
        "        print(f\"‚úÖ Modelo backup encontrado: {backup_model_path}\")\n",
        "        try:\n",
        "            model = YOLO(backup_model_path)\n",
        "            print(\"‚úÖ Modelo backup carregado!\")\n",
        "            return model, 'backup'\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao carregar backup: {e}\")\n",
        "\n",
        "    # Usar modelo pr√©-treinado\n",
        "    print(\"üîÑ Carregando modelo pr√©-treinado YOLOv8...\")\n",
        "    try:\n",
        "        model = YOLO('yolov8n.pt')  # Modelo nano, mais r√°pido para testes\n",
        "        print(\"‚úÖ Modelo pr√©-treinado carregado!\")\n",
        "        return model, 'pretrained'\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao carregar modelo pr√©-treinado: {e}\")\n",
        "        return None, 'error'\n",
        "\n",
        "# Carregar modelo\n",
        "model, model_status = load_or_create_model()\n",
        "\n",
        "def train_model():\n",
        "    \"\"\"Treina o modelo se houver dados dispon√≠veis.\"\"\"\n",
        "    if not model:\n",
        "        print(\"‚ùå Nenhum modelo dispon√≠vel para treinamento\")\n",
        "        return None\n",
        "\n",
        "    if train_count == 0:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado de treino dispon√≠vel. Pulando treinamento.\")\n",
        "        print(\"üí° Para treinar o modelo:\")\n",
        "        print(\"   1. Adicione imagens em data/images/train/\")\n",
        "        print(\"   2. Adicione labels em data/labels/train/\")\n",
        "        print(\"   3. Execute novamente o treinamento\")\n",
        "        return model\n",
        "\n",
        "    if not os.path.exists(dataset_yaml_path):\n",
        "        print(\"‚ùå Arquivo dataset.yaml n√£o encontrado. N√£o √© poss√≠vel treinar.\")\n",
        "        return model\n",
        "\n",
        "    print(f\"\\nüöÄ Iniciando treinamento com {train_count} imagens...\")\n",
        "    print(f\"‚öôÔ∏è Configura√ß√µes:\")\n",
        "    print(f\"   - √âpocas: {training_config['epochs']}\")\n",
        "    print(f\"   - Batch size: {training_config['batch']}\")\n",
        "    print(f\"   - Dispositivo: {training_config['device']}\")\n",
        "    print(f\"   - Workers: {training_config['workers']}\")\n",
        "\n",
        "    try:\n",
        "        # Iniciar treinamento\n",
        "        results = model.train(**training_config)\n",
        "\n",
        "        # Salvar modelo treinado\n",
        "        trained_model_path = './models/best_model.pt'\n",
        "        model.save(trained_model_path)\n",
        "        print(f\"‚úÖ Modelo salvo em: {trained_model_path}\")\n",
        "\n",
        "        # Mostrar m√©tricas de treinamento\n",
        "        if hasattr(results, 'results_dict'):\n",
        "            print(\"\\nüìä Resultados do Treinamento:\")\n",
        "            metrics = results.results_dict\n",
        "            if 'metrics/mAP50(B)' in metrics:\n",
        "                print(f\"   - mAP50: {metrics['metrics/mAP50(B)']:.3f}\")\n",
        "            if 'metrics/mAP50-95(B)' in metrics:\n",
        "                print(f\"   - mAP50-95: {metrics['metrics/mAP50-95(B)']:.3f}\")\n",
        "            if 'metrics/precision(B)' in metrics:\n",
        "                print(f\"   - Precis√£o: {metrics['metrics/precision(B)']:.3f}\")\n",
        "            if 'metrics/recall(B)' in metrics:\n",
        "                print(f\"   - Recall: {metrics['metrics/recall(B)']:.3f}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro durante o treinamento: {e}\")\n",
        "        print(\"üí° Poss√≠veis solu√ß√µes:\")\n",
        "        print(\"   - Verificar se o dataset.yaml est√° correto\")\n",
        "        print(\"   - Reduzir batch_size se houver erro de mem√≥ria\")\n",
        "        print(\"   - Verificar se as imagens e labels est√£o nos diret√≥rios corretos\")\n",
        "        return model\n",
        "\n",
        "# Op√ß√£o de treinamento\n",
        "if model_status == 'pretrained' and train_count > 0:\n",
        "    print(\"\\n‚ùì Deseja treinar o modelo com os dados dispon√≠veis?\")\n",
        "    print(\"   [1] Sim, treinar agora\")\n",
        "    print(\"   [2] N√£o, usar modelo pr√©-treinado\")\n",
        "    print(\"   [3] Treinar automaticamente (recomendado)\")\n",
        "\n",
        "    # Para execu√ß√£o autom√°tica em notebook, treinar se houver dados suficientes\n",
        "    if train_count >= 10:  # M√≠nimo de 10 imagens para treinar\n",
        "        print(\"üîÑ Treinamento autom√°tico iniciado (dados suficientes detectados)\")\n",
        "        model = train_model()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Poucos dados ({train_count} imagens). Recomenda-se pelo menos 10 imagens para treinar.\")\n",
        "        print(\"üîÑ Continuando com modelo pr√©-treinado...\")\n",
        "\n",
        "elif model_status == 'pretrained':\n",
        "    print(\"‚ÑπÔ∏è Usando modelo pr√©-treinado. Nenhum dado de treino dispon√≠vel.\")\n",
        "\n",
        "# Fun√ß√£o para visualizar m√©tricas de treinamento\n",
        "def plot_training_metrics():\n",
        "    \"\"\"Plota m√©tricas de treinamento se dispon√≠veis.\"\"\"\n",
        "    try:\n",
        "        results_path = './models/yolov8_pessoa_celular'\n",
        "        if os.path.exists(results_path):\n",
        "            # Tentar carregar e plotar resultados\n",
        "            print(\"üìä Visualizando m√©tricas de treinamento...\")\n",
        "\n",
        "            # Procurar por arquivos de resultados\n",
        "            results_files = []\n",
        "            for file in os.listdir(results_path):\n",
        "                if file.endswith('.csv') or file.endswith('.png'):\n",
        "                    results_files.append(file)\n",
        "\n",
        "            if results_files:\n",
        "                print(f\"‚úÖ Encontrados arquivos de resultados: {results_files}\")\n",
        "\n",
        "                # Mostrar gr√°ficos se existirem\n",
        "                for file in results_files:\n",
        "                    if file.endswith('.png') and 'results' in file.lower():\n",
        "                        img_path = os.path.join(results_path, file)\n",
        "                        try:\n",
        "                            img = plt.imread(img_path)\n",
        "                            plt.figure(figsize=(12, 8))\n",
        "                            plt.imshow(img)\n",
        "                            plt.title(f'M√©tricas de Treinamento - {file}')\n",
        "                            plt.axis('off')\n",
        "                            plt.show()\n",
        "                        except Exception as e:\n",
        "                            print(f\"‚ö†Ô∏è Erro ao mostrar {file}: {e}\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Nenhum arquivo de resultados encontrado\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Diret√≥rio de resultados n√£o encontrado\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao plotar m√©tricas: {e}\")\n",
        "\n",
        "# Plotar m√©tricas se dispon√≠veis\n",
        "if model_status in ['trained', 'backup']:\n",
        "    plot_training_metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Evo4PmNhBY"
      },
      "source": [
        "# **Avalia√ß√£o do modelo**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knO9uao8gV-H",
        "outputId": "b22faeb1-c6dc-46ce-bb1c-1384981d5656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Configurando avalia√ß√£o do modelo...\n",
            "‚ùå Nenhum modelo dispon√≠vel para avalia√ß√£o\n",
            "‚ö†Ô∏è Dados insuficientes para matriz de confus√£o\n",
            "\n",
            "üß™ Testando modelo...\n",
            "üé® Criando imagens de demonstra√ß√£o...\n",
            "üíæ Imagem de demonstra√ß√£o criada: ./data/images/demo_image.jpg\n",
            "üß™ Testando com imagem de demonstra√ß√£o:\n",
            "‚ùå Modelo n√£o dispon√≠vel\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüìä Configurando avalia√ß√£o do modelo...\")\n",
        "\n",
        "def evaluate_model():\n",
        "    \"\"\"Avalia o modelo no conjunto de teste.\"\"\"\n",
        "    if not model:\n",
        "        print(\"‚ùå Nenhum modelo dispon√≠vel para avalia√ß√£o\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\nüîç Iniciando avalia√ß√£o do modelo...\")\n",
        "\n",
        "    try:\n",
        "        # Avaliar no conjunto de valida√ß√£o/teste\n",
        "        if os.path.exists(dataset_yaml_path) and val_count > 0:\n",
        "            print(f\"üìä Avaliando com {val_count} imagens de valida√ß√£o...\")\n",
        "            test_results = model.val(data=dataset_yaml_path)\n",
        "\n",
        "            # Exibir m√©tricas detalhadas\n",
        "            print(\"\\nüìà M√©tricas de Avalia√ß√£o:\")\n",
        "            if hasattr(test_results, 'box'):\n",
        "                box_metrics = test_results.box\n",
        "                print(f\"   üéØ mAP50: {box_metrics.map50:.3f}\")\n",
        "                print(f\"   üéØ mAP50-95: {box_metrics.map:.3f}\")\n",
        "                print(f\"   üéØ Precis√£o: {box_metrics.mp:.3f}\")\n",
        "                print(f\"   üéØ Recall: {box_metrics.mr:.3f}\")\n",
        "\n",
        "                # M√©tricas por classe se dispon√≠vel\n",
        "                if hasattr(box_metrics, 'ap_class_index') and len(box_metrics.ap_class_index) > 0:\n",
        "                    print(\"\\nüìä M√©tricas por Classe:\")\n",
        "                    class_names = {0: 'person', 67: 'cell phone', 999: 'person_with_phone'}\n",
        "                    for i, class_idx in enumerate(box_metrics.ap_class_index):\n",
        "                        class_name = class_names.get(int(class_idx), f'classe_{class_idx}')\n",
        "                        if i < len(box_metrics.ap):\n",
        "                            print(f\"   üì± {class_name}: mAP50 = {box_metrics.ap[i]:.3f}\")\n",
        "\n",
        "            return test_results\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Dados de valida√ß√£o n√£o dispon√≠veis. Avalia√ß√£o b√°sica ser√° realizada.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro durante avalia√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Executar avalia√ß√£o\n",
        "evaluation_results = evaluate_model()\n",
        "\n",
        "# Fun√ß√£o para criar matriz de confus√£o\n",
        "def create_confusion_matrix():\n",
        "    \"\"\"Cria e exibe matriz de confus√£o se poss√≠vel.\"\"\"\n",
        "    try:\n",
        "        if evaluation_results and hasattr(evaluation_results, 'confusion_matrix'):\n",
        "            cm = evaluation_results.confusion_matrix\n",
        "            if cm is not None:\n",
        "                print(\"\\nüîç Matriz de Confus√£o:\")\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                plt.imshow(cm.matrix, cmap='Blues')\n",
        "                plt.title('Matriz de Confus√£o')\n",
        "                plt.colorbar()\n",
        "\n",
        "                # Adicionar r√≥tulos se poss√≠vel\n",
        "                classes = ['person', 'cell phone', 'person_with_phone']\n",
        "                tick_marks = np.arange(len(classes))\n",
        "                plt.xticks(tick_marks, classes, rotation=45)\n",
        "                plt.yticks(tick_marks, classes)\n",
        "\n",
        "                plt.ylabel('Classe Real')\n",
        "                plt.xlabel('Classe Predita')\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Matriz de confus√£o n√£o dispon√≠vel\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Dados insuficientes para matriz de confus√£o\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao criar matriz de confus√£o: {e}\")\n",
        "\n",
        "# Criar matriz de confus√£o se poss√≠vel\n",
        "create_confusion_matrix()\n",
        "\n",
        "# Fun√ß√£o para testar em imagem individual\n",
        "def test_single_image(image_path, show_result=True, save_result=False):\n",
        "    \"\"\"Testa o modelo em uma √∫nica imagem.\"\"\"\n",
        "    if not model:\n",
        "        print(\"‚ùå Modelo n√£o dispon√≠vel\")\n",
        "        return None\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"‚ùå Imagem n√£o encontrada: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        print(f\"üîç Testando imagem: {os.path.basename(image_path)}\")\n",
        "\n",
        "        # Fazer predi√ß√£o\n",
        "        results = model(image_path, conf=0.5)\n",
        "\n",
        "        # Contar detec√ß√µes\n",
        "        total_detections = 0\n",
        "        people_count = 0\n",
        "        phones_count = 0\n",
        "        people_with_phones = 0\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            if boxes is not None:\n",
        "                total_detections = len(boxes)\n",
        "                for box in boxes:\n",
        "                    cls = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "\n",
        "                    if conf > 0.5:\n",
        "                        if cls == 0:  # person\n",
        "                            people_count += 1\n",
        "                        elif cls == 67:  # cell phone\n",
        "                            phones_count += 1\n",
        "                        elif cls == 999:  # person_with_phone\n",
        "                            people_with_phones += 1\n",
        "\n",
        "        print(f\"   üìä Resultados:\")\n",
        "        print(f\"      üë• Pessoas: {people_count}\")\n",
        "        print(f\"      üì± Celulares: {phones_count}\")\n",
        "        print(f\"      üì±üë• Pessoas com celular: {people_with_phones}\")\n",
        "        print(f\"      üîç Total detec√ß√µes: {total_detections}\")\n",
        "\n",
        "        # Mostrar resultado visualmente\n",
        "        if show_result:\n",
        "            for r in results:\n",
        "                im_array = r.plot()\n",
        "                # Converter BGR para RGB para matplotlib\n",
        "                im_rgb = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                plt.figure(figsize=(12, 8))\n",
        "                plt.imshow(im_rgb)\n",
        "                plt.title(f'Detec√ß√µes - {os.path.basename(image_path)}')\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "        # Salvar resultado se solicitado\n",
        "        if save_result:\n",
        "            output_path = f\"./models/detection_result_{os.path.basename(image_path)}\"\n",
        "            for r in results:\n",
        "                im_array = r.plot()\n",
        "                cv2.imwrite(output_path, im_array)\n",
        "                print(f\"üíæ Resultado salvo em: {output_path}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao testar imagem: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fun√ß√£o para testar em v√≠deo\n",
        "def test_video(video_path, output_path=None, max_frames=100):\n",
        "    \"\"\"Testa o modelo em v√≠deo com limite de frames.\"\"\"\n",
        "    if not model:\n",
        "        print(\"‚ùå Modelo n√£o dispon√≠vel\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"‚ùå V√≠deo n√£o encontrado: {video_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        print(f\"üé• Processando v√≠deo: {os.path.basename(video_path)}\")\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        print(f\"   üìä Total frames: {total_frames}\")\n",
        "        print(f\"   üé¨ FPS: {fps:.1f}\")\n",
        "        print(f\"   ‚è±Ô∏è Processando m√°ximo {max_frames} frames para demonstra√ß√£o\")\n",
        "\n",
        "        # Configurar output se solicitado\n",
        "        out = None\n",
        "        if output_path:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "        frame_count = 0\n",
        "        detection_stats = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret or frame_count >= max_frames:\n",
        "                break\n",
        "\n",
        "            # Processar frame\n",
        "            results = model(frame, conf=0.5, verbose=False)\n",
        "            annotated_frame = results[0].plot()\n",
        "\n",
        "            # Contar detec√ß√µes\n",
        "            total_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
        "            detection_stats.append(total_detections)\n",
        "\n",
        "            # Mostrar progresso\n",
        "            if frame_count % 10 == 0:\n",
        "                print(f\"   üîÑ Frame {frame_count}/{min(max_frames, total_frames)} - Detec√ß√µes: {total_detections}\")\n",
        "\n",
        "            # Salvar frame se output especificado\n",
        "            if out:\n",
        "                out.write(annotated_frame)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        if out:\n",
        "            out.release()\n",
        "            print(f\"üíæ V√≠deo processado salvo em: {output_path}\")\n",
        "\n",
        "        # Estat√≠sticas finais\n",
        "        if detection_stats:\n",
        "            avg_detections = np.mean(detection_stats)\n",
        "            max_detections = max(detection_stats)\n",
        "            print(f\"\\nüìä Estat√≠sticas do V√≠deo:\")\n",
        "            print(f\"   üìà Detec√ß√µes m√©dias por frame: {avg_detections:.1f}\")\n",
        "            print(f\"   üîù M√°ximo de detec√ß√µes em um frame: {max_detections}\")\n",
        "            print(f\"   üé¨ Frames processados: {frame_count}\")\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao processar v√≠deo: {e}\")\n",
        "\n",
        "# Fun√ß√£o para criar imagens de demonstra√ß√£o\n",
        "def create_demo_images():\n",
        "    \"\"\"Cria imagens sint√©ticas para demonstra√ß√£o se n√£o houver dados.\"\"\"\n",
        "    if has_data:\n",
        "        print(\"‚úÖ Dados reais dispon√≠veis. Demonstra√ß√£o com dados reais.\")\n",
        "        return\n",
        "\n",
        "    print(\"üé® Criando imagens de demonstra√ß√£o...\")\n",
        "\n",
        "    try:\n",
        "        # Criar imagem sint√©tica simples\n",
        "        demo_img = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
        "\n",
        "        # Adicionar texto indicativo\n",
        "        cv2.putText(demo_img, 'IMAGEM DE DEMONSTRACAO', (50, 50),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
        "        cv2.putText(demo_img, 'Adicione suas imagens em:', (50, 100),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
        "        cv2.putText(demo_img, 'data/images/', (50, 130),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        # Desenhar formas representativas\n",
        "        cv2.rectangle(demo_img, (200, 200), (300, 350), (255, 0, 0), 2)\n",
        "        cv2.putText(demo_img, 'pessoa', (210, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "\n",
        "        cv2.rectangle(demo_img, (280, 250), (320, 290), (0, 255, 0), 2)\n",
        "        cv2.putText(demo_img, 'celular', (225, 310), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "        # Salvar imagem de demonstra√ß√£o\n",
        "        demo_path = './data/images/demo_image.jpg'\n",
        "        cv2.imwrite(demo_path, demo_img)\n",
        "        print(f\"üíæ Imagem de demonstra√ß√£o criada: {demo_path}\")\n",
        "\n",
        "        return demo_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao criar demonstra√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Testar modelo com dados dispon√≠veis ou demonstra√ß√£o\n",
        "print(\"\\nüß™ Testando modelo...\")\n",
        "\n",
        "# Procurar por imagens de teste\n",
        "test_images = []\n",
        "if val_count > 0:\n",
        "    val_path = os.path.join(images_path, 'val')\n",
        "    test_images = [os.path.join(val_path, f) for f in os.listdir(val_path)\n",
        "                  if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:3]\n",
        "elif test_count > 0:\n",
        "    test_path = os.path.join(images_path, 'test')\n",
        "    test_images = [os.path.join(test_path, f) for f in os.listdir(test_path)\n",
        "                  if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:3]\n",
        "elif has_data:\n",
        "    # Usar imagens da pasta raiz\n",
        "    test_images = [os.path.join(images_path, f) for f in os.listdir(images_path)\n",
        "                  if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:3]\n",
        "\n",
        "if test_images:\n",
        "    print(f\"üñºÔ∏è Testando com {len(test_images)} imagens dispon√≠veis:\")\n",
        "    for img_path in test_images:\n",
        "        test_single_image(img_path, show_result=True)\n",
        "else:\n",
        "    # Criar demonstra√ß√£o\n",
        "    demo_path = create_demo_images()\n",
        "    if demo_path:\n",
        "        print(\"üß™ Testando com imagem de demonstra√ß√£o:\")\n",
        "        test_single_image(demo_path, show_result=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQfwNxkNj0C"
      },
      "source": [
        "# **Consumo do modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VORf-PDVgYLb",
        "outputId": "779c9229-87e2-46bd-ef8a-c0bcc7d5f0d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîå Configurando consumo do modelo...\n",
            "‚ö†Ô∏è M√≥dulo utils.detector n√£o encontrado: No module named 'utils.detector'\n",
            "üí° Criando classe b√°sica para demonstra√ß√£o...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'YOLO' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cd603a0435f4>\u001b[0m in \u001b[0;36msetup_detector_class\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPersonPhoneDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Classe PersonPhoneDetector importada com sucesso!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.detector'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cd603a0435f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Configurar detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_detector_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Teste de funcionamento do detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-cd603a0435f4>\u001b[0m in \u001b[0;36msetup_detector_class\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ö†Ô∏è M√≥dulo utils.detector n√£o encontrado: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üí° Criando classe b√°sica para demonstra√ß√£o...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_basic_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_basic_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-cd603a0435f4>\u001b[0m in \u001b[0;36mcreate_basic_detector\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBasicPersonPhoneDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Configurar detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-cd603a0435f4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, confidence_threshold)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfidence_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfidence_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YOLO' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"\\nüîå Configurando consumo do modelo...\")\n",
        "\n",
        "# Importar classe do m√≥dulo utils se dispon√≠vel\n",
        "def setup_detector_class():\n",
        "    \"\"\"Configura a classe de detec√ß√£o para uso.\"\"\"\n",
        "    try:\n",
        "        from utils.detector import PersonPhoneDetector\n",
        "        print(\"‚úÖ Classe PersonPhoneDetector importada com sucesso!\")\n",
        "\n",
        "        # Criar inst√¢ncia para teste\n",
        "        detector = PersonPhoneDetector(confidence_threshold=0.5)\n",
        "        print(\"‚úÖ Detector configurado e pronto para uso!\")\n",
        "        return detector\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ö†Ô∏è M√≥dulo utils.detector n√£o encontrado: {e}\")\n",
        "        print(\"üí° Criando classe b√°sica para demonstra√ß√£o...\")\n",
        "        return create_basic_detector()\n",
        "\n",
        "def create_basic_detector():\n",
        "    \"\"\"Cria classe b√°sica de detec√ß√£o se o m√≥dulo n√£o existir.\"\"\"\n",
        "    class BasicPersonPhoneDetector:\n",
        "        def __init__(self, model_path=None, confidence_threshold=0.5):\n",
        "            if model_path and os.path.exists(model_path):\n",
        "                self.model = YOLO(model_path)\n",
        "            elif model:\n",
        "                self.model = model\n",
        "            else:\n",
        "                self.model = YOLO('yolov8n.pt')\n",
        "\n",
        "            self.confidence_threshold = confidence_threshold\n",
        "\n",
        "        def detect(self, image_source):\n",
        "            \"\"\"Realiza detec√ß√£o na imagem/v√≠deo.\"\"\"\n",
        "            try:\n",
        "                results = self.model(image_source, conf=self.confidence_threshold)\n",
        "                return results\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro na detec√ß√£o: {e}\")\n",
        "                return None\n",
        "\n",
        "        def count_detections(self, results):\n",
        "            \"\"\"Conta diferentes tipos de detec√ß√µes.\"\"\"\n",
        "            people_count = 0\n",
        "            phones_count = 0\n",
        "            people_with_phones = 0\n",
        "\n",
        "            if not results:\n",
        "                return people_count, phones_count, people_with_phones\n",
        "\n",
        "            for r in results:\n",
        "                boxes = r.boxes\n",
        "                if boxes is not None:\n",
        "                    for box in boxes:\n",
        "                        cls = int(box.cls[0])\n",
        "                        conf = float(box.conf[0])\n",
        "\n",
        "                        if conf > self.confidence_threshold:\n",
        "                            if cls == 0:  # person\n",
        "                                people_count += 1\n",
        "                            elif cls == 67:  # cell phone\n",
        "                                phones_count += 1\n",
        "                            elif cls == 999:  # person_with_phone\n",
        "                                people_with_phones += 1\n",
        "\n",
        "            return people_count, phones_count, people_with_phones\n",
        "\n",
        "        def analyze_image(self, image_path):\n",
        "            \"\"\"An√°lise completa de uma imagem.\"\"\"\n",
        "            results = self.detect(image_path)\n",
        "            if results:\n",
        "                people, phones, people_with_phones = self.count_detections(results)\n",
        "\n",
        "                analysis = {\n",
        "                    'image_path': image_path,\n",
        "                    'total_detections': people + phones + people_with_phones,\n",
        "                    'people': people,\n",
        "                    'phones': phones,\n",
        "                    'people_with_phones': people_with_phones,\n",
        "                    'confidence_threshold': self.confidence_threshold\n",
        "                }\n",
        "\n",
        "                return analysis, results\n",
        "\n",
        "            return None, None\n",
        "\n",
        "    return BasicPersonPhoneDetector()\n",
        "\n",
        "# Configurar detector\n",
        "detector = setup_detector_class()\n",
        "\n",
        "# Teste de funcionamento do detector\n",
        "if detector and test_images:\n",
        "    print(\"\\nüß™ Testando detector personalizado:\")\n",
        "\n",
        "    test_img = test_images[0] if test_images else None\n",
        "    if test_img:\n",
        "        try:\n",
        "            analysis, results = detector.analyze_image(test_img)\n",
        "            if analysis:\n",
        "                print(f\"üìä An√°lise completa da imagem:\")\n",
        "                print(f\"   üì∑ Imagem: {os.path.basename(analysis['image_path'])}\")\n",
        "                print(f\"   üë• Pessoas: {analysis['people']}\")\n",
        "                print(f\"   üì± Celulares: {analysis['phones']}\")\n",
        "                print(f\"   üì±üë• Pessoas com celular: {analysis['people_with_phones']}\")\n",
        "                print(f\"   üîç Total: {analysis['total_detections']} detec√ß√µes\")\n",
        "                print(f\"   üéØ Confian√ßa m√≠nima: {analysis['confidence_threshold']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro no teste: {e}\")\n",
        "\n",
        "print(\"\\nüì± Preparando integra√ß√£o com Streamlit...\")\n",
        "\n",
        "# Fun√ß√£o para criar aplica√ß√£o Streamlit\n",
        "def create_streamlit_app():\n",
        "    \"\"\"Informa√ß√µes sobre a aplica√ß√£o Streamlit.\"\"\"\n",
        "    print(\"‚ÑπÔ∏è A aplica√ß√£o Streamlit est√° dispon√≠vel no arquivo 'app.py'\")\n",
        "    print(\"üöÄ Para executar a aplica√ß√£o:\")\n",
        "    print(\"   1. Instale as depend√™ncias: pip install -r requirements.txt\")\n",
        "    print(\"   2. Execute: streamlit run app.py\")\n",
        "    print(\"   3. Acesse: http://localhost:8501\")\n",
        "\n",
        "    print(\"\\n‚ú® Funcionalidades da aplica√ß√£o:\")\n",
        "    print(\"   üì∑ Upload de imagens para detec√ß√£o\")\n",
        "    print(\"   üé• Upload de v√≠deos para an√°lise\")\n",
        "    print(\"   üìä Visualiza√ß√£o de resultados e m√©tricas\")\n",
        "    print(\"   ‚öôÔ∏è Configura√ß√£o de par√¢metros de detec√ß√£o\")\n",
        "    print(\"   üíæ Download de resultados\")\n",
        "\n",
        "create_streamlit_app()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYascwUEhejA"
      },
      "source": [
        "Requerimentos streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYRqHHjUhgIK"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüì¶ Criando arquivo de depend√™ncias...\")\n",
        "\n",
        "# Criar arquivo requirements.txt atualizado\n",
        "requirements = '''streamlit>=1.28.0\n",
        "ultralytics>=8.0.0\n",
        "opencv-python>=4.8.0\n",
        "Pillow>=9.5.0\n",
        "numpy>=1.24.0\n",
        "pandas>=2.0.0\n",
        "plotly>=5.15.0\n",
        "torch>=2.0.0\n",
        "torchvision>=0.15.0\n",
        "matplotlib>=3.7.0\n",
        "scikit-learn>=1.3.0\n",
        "PyYAML>=6.0\n",
        "albumentations>=1.3.0\n",
        "seaborn>=0.12.0\n",
        "'''\n",
        "\n",
        "try:\n",
        "    with open('./requirements.txt', 'w') as f:\n",
        "        f.write(requirements.strip())\n",
        "    print(\"‚úÖ Arquivo requirements.txt criado/atualizado!\")\n",
        "    print(\"üì¶ Depend√™ncias inclu√≠das:\")\n",
        "    for line in requirements.strip().split('\\n'):\n",
        "        if line.strip():\n",
        "            pkg = line.split('>=')[0]\n",
        "            print(f\"   - {pkg}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao criar requirements.txt: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_anZc1xhVpb"
      },
      "source": [
        "o streamlit propriamente dito, vai ter que estar em outro arquivo no repositorio final chamada app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e5qG9JohM-3"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\nüîç Verificando aplica√ß√£o Streamlit...\")\n",
        "\n",
        "app_py_path = './app.py'\n",
        "if os.path.exists(app_py_path):\n",
        "    print(f\"‚úÖ Aplica√ß√£o Streamlit encontrada: {app_py_path}\")\n",
        "\n",
        "    # Verificar tamanho do arquivo\n",
        "    file_size = os.path.getsize(app_py_path)\n",
        "    print(f\"üìä Tamanho do arquivo: {file_size} bytes\")\n",
        "\n",
        "    if file_size > 1000:  # Se arquivo tem conte√∫do substancial\n",
        "        print(\"‚úÖ Aplica√ß√£o parece estar completa\")\n",
        "        print(\"\\nüöÄ Para executar:\")\n",
        "        print(\"   streamlit run app.py\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Arquivo pode estar incompleto\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Arquivo app.py n√£o encontrado\")\n",
        "    print(\"üí° A aplica√ß√£o Streamlit deve ser criada separadamente\")\n",
        "\n",
        "# Resumo final do projeto\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã RESUMO DO PROJETO - DETEC√á√ÉO DE PESSOAS COM CELULAR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"üìä Dataset:\")\n",
        "print(f\"   - Imagens de treino: {train_count}\")\n",
        "print(f\"   - Imagens de valida√ß√£o: {val_count}\")\n",
        "print(f\"   - Imagens de teste: {test_count}\")\n",
        "\n",
        "print(f\"\\nü§ñ Modelo:\")\n",
        "print(f\"   - Status: {model_status}\")\n",
        "print(f\"   - Dispositivo: {device}\")\n",
        "if model:\n",
        "    print(f\"   - Tipo: {type(model).__name__}\")\n",
        "\n",
        "print(f\"\\nüéØ Classes detectadas:\")\n",
        "print(f\"   - 0: person (pessoa)\")\n",
        "print(f\"   - 67: cell phone (celular)\")\n",
        "print(f\"   - 999: person_with_phone (pessoa com celular)\")\n",
        "\n",
        "print(f\"\\nüìÅ Estrutura do projeto:\")\n",
        "print(f\"   - data/: Dados e configura√ß√µes\")\n",
        "print(f\"   - models/: Modelos treinados\")\n",
        "print(f\"   - utils/: M√≥dulos de apoio\")\n",
        "print(f\"   - docs/: Documenta√ß√£o\")\n",
        "print(f\"   - app.py: Aplica√ß√£o Streamlit\")\n",
        "print(f\"   - requirements.txt: Depend√™ncias\")\n",
        "\n",
        "print(f\"\\n‚úÖ Projeto configurado e pronto para uso!\")\n",
        "print(f\"üí° Pr√≥ximos passos:\")\n",
        "print(f\"   1. Adicionar mais dados de treino se necess√°rio\")\n",
        "print(f\"   2. Treinar modelo customizado\")\n",
        "print(f\"   3. Executar aplica√ß√£o Streamlit\")\n",
        "print(f\"   4. Testar em dados reais\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LtXrRFr4hg3"
      },
      "source": [
        "# **Refer√™ncias**\n",
        "\n",
        "Este √© um item obrigat√≥rio. Inclua aqui o as refer√™ncias, fontes, ou bibliografia e sites/bibliotecas que foram empregados para construir a sua proposta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkpQaW8Ngb2q"
      },
      "source": [
        "# **Refer√™ncias**\n",
        "\n",
        "1. Redmon, J., et al. \"You Only Look Once: Unified, Real-Time Object Detection\" (2016)\n",
        "2. Ultralytics YOLOv8 Documentation: https://docs.ultralytics.com/\n",
        "3. COCO Dataset: https://cocodataset.org/\n",
        "4. Roboflow Documentation: https://docs.roboflow.com/\n",
        "5. OpenCV Documentation: https://docs.opencv.org/\n",
        "6. PyTorch Documentation: https://pytorch.org/docs/\n",
        "7. Streamlit Documentation: https://docs.streamlit.io/\n",
        "8. \"Real-time Object Detection with YOLO\" - Various academic papers\n",
        "9. \"Computer Vision: Algorithms and Applications\" - Richard Szeliski\n",
        "10. \"Deep Learning for Computer Vision\" - Adrian Rosebrock\n",
        "11. Bochkovskiy, A., Wang, C. Y., & Liao, H. Y. M. (2020). \"YOLOv4: Optimal Speed and Accuracy of Object Detection\"\n",
        "12. Wang, C. Y., Bochkovskiy, A., & Liao, H. Y. M. (2023). \"YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\"\n",
        "13. Jocher, G., Chaurasia, A., & Qiu, J. (2023). \"YOLO by Ultralytics\" (Version 8.0.0)\n",
        "14. Lin, T. Y., et al. (2014). \"Microsoft COCO: Common objects in context\"\n",
        "15. He, K., Zhang, X., Ren, S., & Sun, J. (2016). \"Deep residual learning for image recognition\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8crUBC3IQ3U_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BluFtfHuCGzm"
      },
      "outputs": [],
      "source": [
        "#@title **Avalia√ß√£o**\n",
        "GitHub = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Implementacao_Model_Code = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Aplicacao_Streamlit = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Texto_Artigo  = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Video = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Geral = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "2Gqw7hUZHyle",
        "outputId": "cf56d67f-e7bc-42f0-a81d-f1f808967e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nota final do trabalho 7.9\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"alunos\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"tia\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1115677\",\n          \"1115665\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" DANIEL HENRIQUE\",\n          \" ADRIANA FUJITA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 7.9,\n        \"max\": 7.9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "alunos"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b0360d6d-a298-4195-9914-febf9bafcd63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tia</th>\n",
              "      <th>nome</th>\n",
              "      <th>nota</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1115665</td>\n",
              "      <td>ADRIANA FUJITA</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1115677</td>\n",
              "      <td>DANIEL HENRIQUE</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0360d6d-a298-4195-9914-febf9bafcd63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0360d6d-a298-4195-9914-febf9bafcd63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0360d6d-a298-4195-9914-febf9bafcd63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-120aa0b0-48d8-4778-aca7-bace2443a5e8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-120aa0b0-48d8-4778-aca7-bace2443a5e8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-120aa0b0-48d8-4778-aca7-bace2443a5e8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c5110ba6-c42d-43ec-931e-d08b9033ac7e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('alunos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c5110ba6-c42d-43ec-931e-d08b9033ac7e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('alunos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       tia              nome  nota\n",
              "0  1115665    ADRIANA FUJITA   7.9\n",
              "1  1115677   DANIEL HENRIQUE   7.9"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title **Nota Final**\n",
        "\n",
        "nota = 2*GitHub + 4*Implementacao_Model_Code + 2*Aplicacao_Streamlit + 1*Texto_Artigo + 1*Video\n",
        "\n",
        "nota = nota / 10\n",
        "\n",
        "print(f'Nota final do trabalho {nota :.1f}')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alunos = pd.DataFrame()\n",
        "\n",
        "lista_tia = []\n",
        "lista_nome = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
        "\n",
        "alunos['tia'] = lista_tia\n",
        "alunos['nome'] = lista_nome\n",
        "alunos['nota'] = np.round(nota,1)\n",
        "print()\n",
        "display(alunos)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}